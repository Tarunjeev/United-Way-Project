{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b738592-06c1-4816-98d7-dc704193f49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "import os\n",
    "import seaborn as sns\n",
    "import scipy.cluster.hierarchy as spc\n",
    "import pandas_bokeh\n",
    "import pyproj\n",
    "import geopandas as gpd\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from collections import Counter\n",
    "from scipy import stats\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432e5672-82e7-4434-acab-9cabac746df2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "f14ba7b2-a0fc-4e1c-ae9a-68c534ded621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGE THESE TO YOUR PATHS\n",
    "\n",
    "bc_ccare_path = \"~/Desktop/code/Math402W/402DATA/childcare_locations.csv\"\n",
    "environics_path = \"~/Desktop/code/Math402W/402DATA/SFU_CommunityImpactSO/EnvironicsData/DemoStats_2020_SelectVarsData.csv\"\n",
    "so_locations_path = \"~/Desktop/code/Math402W/402DATA/SFU_CommunityImpactSO/SchoolsOutData/SO_map.csv\"\n",
    "so_data_path = \"~/Desktop/code/Math402W/402DATA/SFU_CommunityImpactSO/SchoolsOutData/SO_DirectMetrics.csv\"\n",
    "shape_path = \"~/Desktop/code/Math402W/402DATA/SFU_CommunityImpactSO/GeoData/BoundaryShapeFiles\"\n",
    "postal_da_path = r\"/Users/evanvulliamy/Desktop/code/Math402W/402DATA/dataverse_files/Data/pccfNat_fccpNat_082021.txt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "90be20f1-53cb-41dd-a41d-16d09aea2c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataframes based on the paths\n",
    "\n",
    "bc_ccare_df = pd.read_csv(bc_ccare_path)\n",
    "environics_df = pd.read_csv(environics_path)\n",
    "so_locations_df = pd.read_csv(so_locations_path)\n",
    "so_data_df = pd.read_csv(so_data_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7210ee-1638-486d-aa00-09b968b28840",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "78d40184-4871-42f0-b63e-65d2b3b772f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the first two digits of the CSD or DA\n",
    "def get_province(val):\n",
    "    return str(val)[0:2]\n",
    "\n",
    "# Returns\n",
    "def get_census_area(val):\n",
    "    return str(val)[2:4]\n",
    "\n",
    "# Adds a space to format postal codes xxxxxx -> xxx xxx\n",
    "def add_space(string):\n",
    "    if len(string) >= 7:\n",
    "        return string\n",
    "    return string[0:3] + \" \" + string[3:6]\n",
    "\n",
    "# Raise all characters to upper case\n",
    "def to_upper(string):\n",
    "    return string.upper()\n",
    "\n",
    "# Separate a string by commas\n",
    "def split_fn(string):\n",
    "    return string.split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "a2870bec-99a5-491d-b75f-8186cdfd0f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables\n",
    "\n",
    "total_area = \"ECYASQKM\" # DROP\n",
    "total_land_area = \"ECYALSQKM\" # DROP \n",
    "total_pop_1 = \"ECYBASPOP\" # SCALAR\n",
    "total_pop_2 = \"ECYPTAPOP\" # SCALAR\n",
    "total_5_9 = \"ECYPTA_5_9\" # NEEDS SCALING total_pop_1\n",
    "total_10_14 = \"ECYPTA1014\" # DROP\n",
    "total_60_64 = \"ECYPTA6064\" # DROP\n",
    "total_65_69 = \"ECYPTA6569\" # DROP\n",
    "total_70_74 = \"ECYPTA7074\" # DROP\n",
    "total_75_79 = \"ECYPTA7579\" # DROP\n",
    "total_80_84 = \"ECYPTA8084\" # DROP\n",
    "total_85_plus = \"ECYPTA85P\" # DROP\n",
    "total_fam_households = \"ECYHTYFHT\" # SCALAR <- should we use this one over census families??\n",
    "total_65_alone = \"ECYHTYN65A\" # DROP\n",
    "\n",
    "census_families = \"ECYCFSCF\" # SCALAR\n",
    "cf_with_children = \"ECYCFSCWC\" # NEEDS SCALING census_families\n",
    "lone_parent = \"ECYCFSLP\" # NEEDS SCALING census_families\n",
    "lp_one_child = \"ECYCFSLP1C\" # NEEDS SCALING census_families\n",
    "lp_two_child = \"ECYCFSLP2C\" # NEEDS SCALING census_families\n",
    "lp_three_more_child = \"ECYCFSLP3C\" # NEEDS SCALING census_families\n",
    "percent_children_home = \"ECYHFSWC\" # KEEP AS IS\n",
    "total_kids_home = \"ECYCHAKIDS\" # SCALAR\n",
    "kids_home_5_9 = \"ECYCHA_5_9\" # NEEDS SCALING total_kids_home\n",
    "kids_home_10_14 = \"ECYCHA1014\" # DROP\n",
    "avg_child_per_fam = \"ECYCHACFCH\" # KEEP AS IS\n",
    "\n",
    "\n",
    "house_pop_5_year_mobility = \"ECYMOBHPOP\" # DROP\n",
    "movers = \"ECYMOBMOV\" # DROP\n",
    "household_tenure = \"ECYTENHHD\" # DROP\n",
    "rented = \"ECYTENRENT\" # DROP\n",
    "band_housing = \"ECYTENBAND\" # DROP\n",
    "total_condo_status = \"ECYCDOHHD\" # DROP\n",
    "in_condo = \"ECYCDOCO\" # DROP\n",
    "rented_in_condo = \"ECYCDORECO\" # DROP\n",
    "\n",
    "total_households = \"ECYHNIHHD\" # SCALAR\n",
    "income_0_19 = \"ECYHNI_020\" # ADD WITH income_20_39 NEEDS SCALING total_households\n",
    "income_20_39 = \"ECYHNI2040\" # ADD WITH income income_0_19 NEEDS SCALING total_households\n",
    "income_40_59 = \"ECYHNI4060\" # DROP \n",
    "income_60_79 = \"ECYHNI6080\" # DROP\n",
    "income_80_100 = \"ECYHNIX100\" # DROP \n",
    "median_income = \"ECYHNIMED\" # KEEP AS IS\n",
    "fifteen_older_income = \"ECYPNIHP15\" # DROP\n",
    "without_income = \"ECYPNININ\" # DROP <- FOR NOW, might decide against this\n",
    "avg_income = \"ECYPNIAVG\" # KEEP AS IS\n",
    "unemployment_rate = \"ECYACTUR\" # KEEP AS IS\n",
    "travel_to_work = \"ECYTRAHPL\" # SCALAR\n",
    "travel_to_work_transit = \"ECYTRAPUBL\" # NEEDS SCALING travel_to_work\n",
    "house_pop_vis_minority = \"ECYVISHPOP\" # SCALAR\n",
    "vis_minority_total = \"ECYVISVM\" # SCALAR\n",
    "vis_minority_blk = \"ECYVISBLCK\" # NEEDS SCALING vis_minority_total\n",
    "house_pop_abrgnl = \"ECYAIDHPOP\" # NEEDS SCALING total_households\n",
    "abrgnl_id = \"ECYAIDABO\" # NEEDS SCALING vis_minority_total\n",
    "pop_knowledge_off_lang = \"ECYKNOHPOP\" # SCAlAR\n",
    "no_off_lang = \"ECYKNONEF\" # NEEDS SCALING pop_knowledge_off_lang\n",
    "household_recent_immigrant = \"ECYRIMHPOP\" # NEEDS SCALING total_households\n",
    "total_recent_immigrant = \"ECYRIMRIM\" # NEEDS SCALING total_pop_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "1317acd2-feab-458b-a2d7-eb30d9ab1a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT: \n",
    "# df: a dataframe of Environics data or Shapefile data\n",
    "# area: Either PRCDDA (dissemination areas) or PRCDCSD (census subdivisions)\n",
    "# OUTPUT:\n",
    "# A dataframe consisting of only rows belonging to BC and either DA or CSDs\n",
    "\n",
    "def get_rows(df, area):\n",
    "    return_df = df.loc[df.GEO == area]\n",
    "    new_df = return_df.copy()\n",
    "    new_df['prov'] = new_df['CODE'].apply(get_province)\n",
    "    new_df = new_df[new_df.prov == \"59\"]\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "8f9ec392-1d30-4d2a-89ad-b292a15dfd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSD = get_rows(environics_df, \"PRCDCSD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d2e216-e267-4934-ac58-4a43f96092f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "c390d01c-893b-4b06-9a51-f61e587b34a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT:\n",
    "# df: A dataframe of environics data (environics_df)\n",
    "# drop_list: a list of all variables that do not need to be considered\n",
    "# OUTPUT:\n",
    "# An environics dataframe of variables scaled by relevant populations\n",
    "\n",
    "# IDEAS: Change low income to be based on distance from median income?\n",
    "\n",
    "# NOTES: This is information that needs to be saved in the mega-csv (or a separate csv file)\n",
    "\n",
    "def scale_and_drop(df, drop_list):\n",
    "    scaled_df = df.copy()\n",
    "    scaled_df['unscaled_5_9'] = df[total_5_9]\n",
    "    scaled_df[total_5_9] = df[total_5_9] / df[total_pop_1]\n",
    "    scaled_df[lone_parent] =  df[lone_parent] / df[census_families]\n",
    "    scaled_df[kids_home_5_9] =  df[kids_home_5_9] / df[total_kids_home]\n",
    "    scaled_df['low_income'] =  (df[income_0_19] + df[income_20_39]) / df[total_households]\n",
    "    scaled_df[travel_to_work_transit] =  df[travel_to_work_transit] / df[travel_to_work]\n",
    "    scaled_df[vis_minority_blk] =  df[vis_minority_blk] / df[vis_minority_total]\n",
    "    scaled_df[house_pop_abrgnl] =  df[house_pop_abrgnl] / df[total_households]\n",
    "    scaled_df[abrgnl_id] =  df[abrgnl_id] / df[vis_minority_total]\n",
    "    scaled_df[no_off_lang] =  df[no_off_lang] / df[pop_knowledge_off_lang]\n",
    "    scaled_df[household_recent_immigrant] =  df[household_recent_immigrant] / df[total_households]\n",
    "    scaled_df[total_recent_immigrant] =  df[total_recent_immigrant] / df[total_pop_1]\n",
    "    \n",
    "    # Drop scalars\n",
    "    # scaled_df = scaled_df.drop([total_pop_1, total_pop_2, total_fam_households, census_families, total_kids_home,\n",
    "    #                             total_households, travel_to_work, house_pop_vis_minority,\n",
    "    #                              vis_minority_total, pop_knowledge_off_lang, income_0_19, income_20_39, 'prov', 'GEO'], axis = 1)\n",
    "    scaled_df = scaled_df.drop(['prov', 'GEO', income_0_19, income_20_39], axis = 1)\n",
    "    # Drop extra cols\n",
    "    scaled_df = scaled_df.drop(drop_list, axis = 1)\n",
    "    \n",
    "    # Reformat cells that are inf after dividing by zero\n",
    "    scaled_df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    scaled_df = scaled_df.fillna(0)\n",
    "    scaled_df = rename(scaled_df)\n",
    "    \n",
    "    return scaled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "0a8a4ce5-576a-4a54-933b-36ab1cd20557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: an environics dataframe\n",
    "# Output: a dataframe with renamed columns \n",
    "# Used in scale_and_drop\n",
    "def rename(df):\n",
    "    df = df.rename(columns={total_5_9 : \"total_5_9\", total_10_14 : \"total_10_14\", cf_with_children : \"cf_with_children\", lone_parent : \"lone_parent\",\n",
    "                  lp_one_child : \"lp_one_child\", lp_two_child : \"lp_two_child\", lp_three_more_child : \"lp_three_more_child\", kids_home_5_9 : \"total_kids_home\",\n",
    "                  kids_home_10_14 : \"total_kids_home\", travel_to_work_transit : \"travel_to_work_transit\", vis_minority_blk : \"vis_minority_blk\",\n",
    "                  house_pop_abrgnl : \"house_pop_abrgnl\", abrgnl_id : \"abrgnl_id\", no_off_lang : \"no_off_lang\", household_recent_immigrant : \"household_recent_immigrant\",\n",
    "                  total_recent_immigrant : \"total_recent_immigrant\", percent_children_home : \"percent_children_home\", avg_child_per_fam : \"avg_child_per_fam\",\n",
    "                  median_income : \"median_income\", avg_income : \"avg_income\", unemployment_rate : \"unemployment_rate\", total_pop_1 : \"total_pop_1_SCALAR\", total_pop_2 : \"total_pop_2_SCALAR\",\n",
    "                  total_fam_households : \"total_fam_households_SCALAR\", census_families : \"census_families_SCALAR\", total_kids_home : \"total_kids_home_SCALAR\", total_households : \"total_households_SCALAR\",\n",
    "                  travel_to_work : \"travel_to_work_SCALAR\", house_pop_vis_minority : \"house_pop_vis_minority_SCALAR\", vis_minority_total : \"vis_minority_total_SCALAR\", \n",
    "                  pop_knowledge_off_lang : \"pop_knowledge_off_lang_SCALAR\", })\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3333e746-bb3a-47da-961f-9c177cf500b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "a26d4f62-2fd6-4201-9e15-32697feb5e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: a dataframe that has been run through \"scale and drop\"\n",
    "# Output: a 2d matrix representing the correlation of each variable with one another\n",
    "\n",
    "def correlation(df):\n",
    "    \n",
    "    temp_df = df.copy()\n",
    "    temp_df = temp_df.drop(['CODE'], axis=1)\n",
    "    \n",
    "    column_names = temp_df.columns\n",
    "    print(column_names)\n",
    "    \n",
    "    values_scaled = []\n",
    "\n",
    "    for var_i in column_names:\n",
    "        if var_i == 'CODE':\n",
    "            continue\n",
    "        for var_j in column_names:\n",
    "            if var_j == 'CODE':\n",
    "                continue\n",
    "            correlation_coef = stats.linregress(temp_df[var_i], temp_df[var_j]).rvalue\n",
    "            values_scaled.append(correlation_coef)\n",
    "    \n",
    "    dims = len(column_names)\n",
    "    \n",
    "    values_scaled = np.array(values_scaled)\n",
    "    values_scaled = values_scaled.reshape(dims,dims)\n",
    "    plot_df = pd.DataFrame(data = values_scaled, columns = column_names, index = column_names)\n",
    "    \n",
    "    plt.rcParams[\"figure.figsize\"] = (30,20)\n",
    "    plt.title(\"Correlation Coefficient\", fontsize=20)\n",
    "    sns.heatmap(plot_df, annot = True)\n",
    "    plt.xticks(rotation=45, fontsize = 15)\n",
    "    plt.yticks(fontsize = 10)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "06e60724-1d73-47ac-9eb5-19397184f561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: a dataframe that has been run through \"scale and drop\"\n",
    "# Output: The table of correlated clusters, and the related dendrogram\n",
    "\n",
    "# NOTES: This is information that needs to be saved in the mega-csv (or a separate csv file)\n",
    "\n",
    "def display_cor_clusters(df):\n",
    "    \n",
    "    # Code referenced from:\n",
    "    # https://stackoverflow.com/questions/52787431/create-clusters-using-correlation-matrix-in-python\n",
    "    cols = []\n",
    "    df_scaled = df.drop(['CODE'], axis=1)\n",
    "    for elems in df_scaled.columns:\n",
    "        if elems[-6:] != 'SCALAR':\n",
    "            cols.append(elems)\n",
    "    \n",
    "    df_scaled = df_scaled[cols]\n",
    "    corr = df_scaled.corr().values\n",
    "    \n",
    "    pdist = spc.distance.pdist(corr)\n",
    "    linkage = spc.linkage(pdist, method='complete')\n",
    "    idx_scaled = spc.fcluster(linkage, 0.5 * pdist.max(), 'distance')\n",
    "    plt.figure(figsize=(20,40))\n",
    "    \n",
    "    dn = spc.dendrogram(linkage)\n",
    "    spc.set_link_color_palette(['m', 'c', 'y', 'k'])\n",
    "    # fig, axes = plt.subplots(1, 2, figsize=(8, 3))\n",
    "    # dn1 = spc.dendrogram(dn, ax=axes[0], above_threshold_color='y',\n",
    "    #                            orientation='top')\n",
    "    # dn2 = spc.dendrogram(dn, ax=axes[1],\n",
    "    #                            above_threshold_color='#bcbddc',\n",
    "    #                            orientation='right')\n",
    "    spc.set_link_color_palette(None)  # reset to default after use\n",
    "    plt.show()\n",
    "    \n",
    "    # print(pdist, linkage, idx_scaled)\n",
    "    scaled_cols = {\"var\" : df_scaled.columns, \"cluster\" : idx_scaled}\n",
    "    df_scaled = pd.DataFrame(data=scaled_cols)\n",
    "    sorted_scaled = df_scaled.sort_values(by='cluster')\n",
    "    print(sorted_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "f0fcfb4d-7e85-440a-b1a9-f6c216c96690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: \n",
    "# df: a scaled df, with columns [CODE, chosen_var_1, chosen_var_2, ... , chosen_var_n]\n",
    "# num_intervals: the number of intervals to divide the data into (in our project we used 10)\n",
    "# weights: a list of n weights for each of the variables \n",
    "\n",
    "# Output: \n",
    "# a dataframe with the original variables and the scores produced for each variable\n",
    "\n",
    "# NOTES: This is information that needs to be saved in the mega-csv (or a separate csv file)\n",
    "\n",
    "def create_score_table(df, num_intervals, weights):\n",
    "    # This is some code for the scoring process\n",
    "    # It creates a new dataframe for the scores of each variable\n",
    "    # n is the number of itervals\n",
    "    # num_vars is the number of variables used\n",
    "    print(df)\n",
    "    n = num_intervals\n",
    "    num_vars = len(weights)\n",
    "    meta_data = {}\n",
    "    \n",
    "    # calculate the interval size (max - min) / n\n",
    "    for col in df.columns:\n",
    "        if col == 'CODE':\n",
    "            continue\n",
    "        meta_data[col] = (df[col].max() - df[col].min()) / n\n",
    "\n",
    "    # Create the score table\n",
    "    score_df = df[['CODE']]\n",
    "    score_list = []\n",
    "    for keys in meta_data.keys():\n",
    "        score_list.append('weighted_{}'.format(keys))\n",
    "    score_df[score_list] = 0\n",
    "    \n",
    "    \n",
    "    # iterate through and score each variable\n",
    "    scoring = score_df.copy()\n",
    "    for index, col in enumerate(df.columns):\n",
    "        print(index, col)\n",
    "        for i in range(n):\n",
    "            if col == 'CODE':\n",
    "                continue    \n",
    "            if col != 'avg_income' and col != 'median_income':\n",
    "                # Higher values mean higher scores\n",
    "                scoring.loc[df[col].between(meta_data.get(col) * i, meta_data.get(col) * (i + 1)), \n",
    "                            ['weighted_{}'.format(col)]] = (i+1)\n",
    "            else:\n",
    "                # Higher values mean lower scores\n",
    "                scoring.loc[df[col].between(meta_data.get(col) * i, meta_data.get(col) * (i + 1)), \n",
    "                            ['weighted_{}'.format(col)]] = num_intervals - i\n",
    "                \n",
    "    pre_scale = scoring[['weighted_{}'.format(keys) for keys in meta_data.keys()]].copy()\n",
    "    pre_scale = pre_scale.set_axis(['unscaled_score_{}'.format(keys) for keys in meta_data.keys()], axis='columns', inplace=False)\n",
    "    pre_scale['CODE'] = df['CODE']\n",
    "    \n",
    "    scoring = weights * scoring[['weighted_{}'.format(keys) for keys in meta_data.keys()]]\n",
    "    scoring['total'] = scoring.sum(axis = 1)\n",
    "    scoring['percent_total'] = scoring['total'] / num_intervals\n",
    "    scoring['CODE'] = df['CODE']\n",
    "    return_df = scoring.merge(df, left_on='CODE', right_on='CODE')\n",
    "    return_df = return_df.merge(pre_scale, left_on='CODE', right_on='CODE')\n",
    "    return_df = return_df.sort_values(by='total', ascending=False)\n",
    "    return return_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "1a3e9ec6-cdad-40a2-bc86-45e79eba39b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_list = [total_area, total_land_area, total_60_64, total_65_69, total_70_74, total_75_79, \n",
    " total_80_84, total_85_plus, total_65_alone, house_pop_5_year_mobility,  movers, \n",
    " household_tenure, rented, band_housing, total_condo_status, in_condo, rented_in_condo, \n",
    " income_40_59, income_60_79, income_80_100, fifteen_older_income, without_income, \n",
    " kids_home_10_14, total_10_14, lp_one_child, lp_two_child, lp_three_more_child, cf_with_children]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad5fd79-61fe-450c-8463-d4d6e0fb51ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "9d19ca8c-8d98-4538-9958-1834fb6d55d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df_csd = scale_and_drop(CSD, drop_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "7dacec08-7224-4227-a154-a527ea5e04a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CODE</th>\n",
       "      <th>total_pop_1_SCALAR</th>\n",
       "      <th>total_pop_2_SCALAR</th>\n",
       "      <th>total_5_9</th>\n",
       "      <th>total_fam_households_SCALAR</th>\n",
       "      <th>census_families_SCALAR</th>\n",
       "      <th>lone_parent</th>\n",
       "      <th>percent_children_home</th>\n",
       "      <th>total_kids_home_SCALAR</th>\n",
       "      <th>total_kids_home</th>\n",
       "      <th>...</th>\n",
       "      <th>vis_minority_total_SCALAR</th>\n",
       "      <th>vis_minority_blk</th>\n",
       "      <th>house_pop_abrgnl</th>\n",
       "      <th>abrgnl_id</th>\n",
       "      <th>pop_knowledge_off_lang_SCALAR</th>\n",
       "      <th>no_off_lang</th>\n",
       "      <th>household_recent_immigrant</th>\n",
       "      <th>total_recent_immigrant</th>\n",
       "      <th>unscaled_5_9</th>\n",
       "      <th>low_income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29477</th>\n",
       "      <td>5943816.0</td>\n",
       "      <td>237</td>\n",
       "      <td>237</td>\n",
       "      <td>0.071730</td>\n",
       "      <td>55</td>\n",
       "      <td>59</td>\n",
       "      <td>0.152542</td>\n",
       "      <td>56</td>\n",
       "      <td>80</td>\n",
       "      <td>0.212500</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.246575</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>237</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.246575</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17</td>\n",
       "      <td>0.328767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29537</th>\n",
       "      <td>5943817.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29597</th>\n",
       "      <td>5943835.0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29657</th>\n",
       "      <td>5943836.0</td>\n",
       "      <td>73</td>\n",
       "      <td>73</td>\n",
       "      <td>0.068493</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29717</th>\n",
       "      <td>5943837.0</td>\n",
       "      <td>461</td>\n",
       "      <td>461</td>\n",
       "      <td>0.047722</td>\n",
       "      <td>146</td>\n",
       "      <td>146</td>\n",
       "      <td>0.328767</td>\n",
       "      <td>33</td>\n",
       "      <td>162</td>\n",
       "      <td>0.135802</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.822581</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>452</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.822581</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22</td>\n",
       "      <td>0.645161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72557</th>\n",
       "      <td>5915015.0</td>\n",
       "      <td>216320</td>\n",
       "      <td>216320</td>\n",
       "      <td>0.041841</td>\n",
       "      <td>57981</td>\n",
       "      <td>62174</td>\n",
       "      <td>0.165873</td>\n",
       "      <td>48</td>\n",
       "      <td>65889</td>\n",
       "      <td>0.131904</td>\n",
       "      <td>...</td>\n",
       "      <td>170221</td>\n",
       "      <td>0.009447</td>\n",
       "      <td>2.708127</td>\n",
       "      <td>0.011597</td>\n",
       "      <td>214443</td>\n",
       "      <td>0.111176</td>\n",
       "      <td>2.708127</td>\n",
       "      <td>0.061035</td>\n",
       "      <td>9051</td>\n",
       "      <td>0.257776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72588</th>\n",
       "      <td>5915020.0</td>\n",
       "      <td>19383</td>\n",
       "      <td>19383</td>\n",
       "      <td>0.045194</td>\n",
       "      <td>4156</td>\n",
       "      <td>4252</td>\n",
       "      <td>0.200611</td>\n",
       "      <td>42</td>\n",
       "      <td>4677</td>\n",
       "      <td>0.177892</td>\n",
       "      <td>...</td>\n",
       "      <td>12352</td>\n",
       "      <td>0.006477</td>\n",
       "      <td>2.526659</td>\n",
       "      <td>0.025502</td>\n",
       "      <td>17439</td>\n",
       "      <td>0.063249</td>\n",
       "      <td>2.526659</td>\n",
       "      <td>0.038745</td>\n",
       "      <td>876</td>\n",
       "      <td>0.393799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72619</th>\n",
       "      <td>5915022.0</td>\n",
       "      <td>682404</td>\n",
       "      <td>682404</td>\n",
       "      <td>0.033958</td>\n",
       "      <td>162731</td>\n",
       "      <td>171041</td>\n",
       "      <td>0.157477</td>\n",
       "      <td>29</td>\n",
       "      <td>153585</td>\n",
       "      <td>0.143868</td>\n",
       "      <td>...</td>\n",
       "      <td>369263</td>\n",
       "      <td>0.022799</td>\n",
       "      <td>2.197987</td>\n",
       "      <td>0.042352</td>\n",
       "      <td>668111</td>\n",
       "      <td>0.067013</td>\n",
       "      <td>2.197987</td>\n",
       "      <td>0.037324</td>\n",
       "      <td>23173</td>\n",
       "      <td>0.249262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72650</th>\n",
       "      <td>5915025.0</td>\n",
       "      <td>259715</td>\n",
       "      <td>259715</td>\n",
       "      <td>0.041700</td>\n",
       "      <td>65261</td>\n",
       "      <td>69153</td>\n",
       "      <td>0.161280</td>\n",
       "      <td>41</td>\n",
       "      <td>70224</td>\n",
       "      <td>0.148382</td>\n",
       "      <td>...</td>\n",
       "      <td>174255</td>\n",
       "      <td>0.027465</td>\n",
       "      <td>2.566490</td>\n",
       "      <td>0.028338</td>\n",
       "      <td>256726</td>\n",
       "      <td>0.069346</td>\n",
       "      <td>2.566490</td>\n",
       "      <td>0.057609</td>\n",
       "      <td>10830</td>\n",
       "      <td>0.259042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72680</th>\n",
       "      <td>5915029.0</td>\n",
       "      <td>81568</td>\n",
       "      <td>81568</td>\n",
       "      <td>0.039623</td>\n",
       "      <td>20019</td>\n",
       "      <td>20778</td>\n",
       "      <td>0.151651</td>\n",
       "      <td>30</td>\n",
       "      <td>17861</td>\n",
       "      <td>0.168244</td>\n",
       "      <td>...</td>\n",
       "      <td>35012</td>\n",
       "      <td>0.070547</td>\n",
       "      <td>2.246035</td>\n",
       "      <td>0.075488</td>\n",
       "      <td>80298</td>\n",
       "      <td>0.027535</td>\n",
       "      <td>2.246035</td>\n",
       "      <td>0.068863</td>\n",
       "      <td>3232</td>\n",
       "      <td>0.239294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>737 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            CODE  total_pop_1_SCALAR  total_pop_2_SCALAR  total_5_9  \\\n",
       "29477  5943816.0                 237                 237   0.071730   \n",
       "29537  5943817.0                   0                   0   0.000000   \n",
       "29597  5943835.0                  10                  10   0.200000   \n",
       "29657  5943836.0                  73                  73   0.068493   \n",
       "29717  5943837.0                 461                 461   0.047722   \n",
       "...          ...                 ...                 ...        ...   \n",
       "72557  5915015.0              216320              216320   0.041841   \n",
       "72588  5915020.0               19383               19383   0.045194   \n",
       "72619  5915022.0              682404              682404   0.033958   \n",
       "72650  5915025.0              259715              259715   0.041700   \n",
       "72680  5915029.0               81568               81568   0.039623   \n",
       "\n",
       "       total_fam_households_SCALAR  census_families_SCALAR  lone_parent  \\\n",
       "29477                           55                      59     0.152542   \n",
       "29537                            0                       0     0.000000   \n",
       "29597                            1                       2     0.500000   \n",
       "29657                            0                       0     0.000000   \n",
       "29717                          146                     146     0.328767   \n",
       "...                            ...                     ...          ...   \n",
       "72557                        57981                   62174     0.165873   \n",
       "72588                         4156                    4252     0.200611   \n",
       "72619                       162731                  171041     0.157477   \n",
       "72650                        65261                   69153     0.161280   \n",
       "72680                        20019                   20778     0.151651   \n",
       "\n",
       "       percent_children_home  total_kids_home_SCALAR  total_kids_home  ...  \\\n",
       "29477                     56                      80         0.212500  ...   \n",
       "29537                      0                       0         0.000000  ...   \n",
       "29597                    100                       3         0.000000  ...   \n",
       "29657                      0                       0         0.000000  ...   \n",
       "29717                     33                     162         0.135802  ...   \n",
       "...                      ...                     ...              ...  ...   \n",
       "72557                     48                   65889         0.131904  ...   \n",
       "72588                     42                    4677         0.177892  ...   \n",
       "72619                     29                  153585         0.143868  ...   \n",
       "72650                     41                   70224         0.148382  ...   \n",
       "72680                     30                   17861         0.168244  ...   \n",
       "\n",
       "       vis_minority_total_SCALAR  vis_minority_blk  house_pop_abrgnl  \\\n",
       "29477                          0          0.000000          3.246575   \n",
       "29537                          0          0.000000          0.000000   \n",
       "29597                          0          0.000000         10.000000   \n",
       "29657                          0          0.000000          4.000000   \n",
       "29717                          0          0.000000          1.822581   \n",
       "...                          ...               ...               ...   \n",
       "72557                     170221          0.009447          2.708127   \n",
       "72588                      12352          0.006477          2.526659   \n",
       "72619                     369263          0.022799          2.197987   \n",
       "72650                     174255          0.027465          2.566490   \n",
       "72680                      35012          0.070547          2.246035   \n",
       "\n",
       "       abrgnl_id  pop_knowledge_off_lang_SCALAR  no_off_lang  \\\n",
       "29477   0.000000                            237     0.000000   \n",
       "29537   0.000000                              0     0.000000   \n",
       "29597   0.000000                             10     0.000000   \n",
       "29657   0.000000                              4     0.000000   \n",
       "29717   0.000000                            452     0.000000   \n",
       "...          ...                            ...          ...   \n",
       "72557   0.011597                         214443     0.111176   \n",
       "72588   0.025502                          17439     0.063249   \n",
       "72619   0.042352                         668111     0.067013   \n",
       "72650   0.028338                         256726     0.069346   \n",
       "72680   0.075488                          80298     0.027535   \n",
       "\n",
       "       household_recent_immigrant  total_recent_immigrant  unscaled_5_9  \\\n",
       "29477                    3.246575                0.000000            17   \n",
       "29537                    0.000000                0.000000             0   \n",
       "29597                   10.000000                0.000000             2   \n",
       "29657                    4.000000                0.000000             5   \n",
       "29717                    1.822581                0.000000            22   \n",
       "...                           ...                     ...           ...   \n",
       "72557                    2.708127                0.061035          9051   \n",
       "72588                    2.526659                0.038745           876   \n",
       "72619                    2.197987                0.037324         23173   \n",
       "72650                    2.566490                0.057609         10830   \n",
       "72680                    2.246035                0.068863          3232   \n",
       "\n",
       "       low_income  \n",
       "29477    0.328767  \n",
       "29537    0.000000  \n",
       "29597    0.000000  \n",
       "29657    0.000000  \n",
       "29717    0.645161  \n",
       "...           ...  \n",
       "72557    0.257776  \n",
       "72588    0.393799  \n",
       "72619    0.249262  \n",
       "72650    0.259042  \n",
       "72680    0.239294  \n",
       "\n",
       "[737 rows x 28 columns]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df_csd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "e86e81d9-4f50-4d12-ba82-bae4ae806777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display_cor_clusters(data_df_csd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "41c01b1c-393e-4ba9-83df-eda8bfbf6a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = [0.05, 0.05, 0.2, 0.1, 0.175, 0.1, 0.175, 0.15]\n",
    "forced_choices = ['household_recent_immigrant', 'vis_minority_blk', 'abrgnl_id', 'no_off_lang', 'low_income', 'median_income', 'lone_parent', 'total_kids_home']\n",
    "input_df = data_df_csd[['CODE'] + forced_choices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "a57b2229-c160-4448-b381-305f38d2f975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            CODE  household_recent_immigrant  vis_minority_blk  abrgnl_id  \\\n",
      "29477  5943816.0                    3.246575          0.000000   0.000000   \n",
      "29537  5943817.0                    0.000000          0.000000   0.000000   \n",
      "29597  5943835.0                   10.000000          0.000000   0.000000   \n",
      "29657  5943836.0                    4.000000          0.000000   0.000000   \n",
      "29717  5943837.0                    1.822581          0.000000   0.000000   \n",
      "...          ...                         ...               ...        ...   \n",
      "72557  5915015.0                    2.708127          0.009447   0.011597   \n",
      "72588  5915020.0                    2.526659          0.006477   0.025502   \n",
      "72619  5915022.0                    2.197987          0.022799   0.042352   \n",
      "72650  5915025.0                    2.566490          0.027465   0.028338   \n",
      "72680  5915029.0                    2.246035          0.070547   0.075488   \n",
      "\n",
      "       no_off_lang  low_income  median_income  lone_parent  total_kids_home  \n",
      "29477     0.000000    0.328767       56261.36     0.152542         0.212500  \n",
      "29537     0.000000    0.000000           0.00     0.000000         0.000000  \n",
      "29597     0.000000    0.000000       79381.78     0.500000         0.000000  \n",
      "29657     0.000000    0.000000      131401.23     0.000000         0.000000  \n",
      "29717     0.000000    0.645161       31636.67     0.328767         0.135802  \n",
      "...            ...         ...            ...          ...              ...  \n",
      "72557     0.111176    0.257776       77285.87     0.165873         0.131904  \n",
      "72588     0.063249    0.393799       57984.51     0.200611         0.177892  \n",
      "72619     0.067013    0.249262       80723.41     0.157477         0.143868  \n",
      "72650     0.069346    0.259042       76955.71     0.161280         0.148382  \n",
      "72680     0.027535    0.239294       76805.88     0.151651         0.168244  \n",
      "\n",
      "[737 rows x 9 columns]\n",
      "0 CODE\n",
      "1 household_recent_immigrant\n",
      "2 vis_minority_blk\n",
      "3 abrgnl_id\n",
      "4 no_off_lang\n",
      "5 low_income\n",
      "6 median_income\n",
      "7 lone_parent\n",
      "8 total_kids_home\n"
     ]
    }
   ],
   "source": [
    "table = create_score_table(input_df, 10, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "a2fc1eb8-4b35-4e7c-88d2-164914658caf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "656    0.000000\n",
       "725    0.000000\n",
       "553    0.000000\n",
       "653    0.000000\n",
       "136    0.000000\n",
       "         ...   \n",
       "288    0.000000\n",
       "423    0.004167\n",
       "3      0.000000\n",
       "611    0.018762\n",
       "608    0.013804\n",
       "Name: no_off_lang, Length: 737, dtype: float64"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table['no_off_lang']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de6f75c-42cf-4ba1-a44a-94ff23bc88e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "d4bf77db-7d06-4729-ae52-40c8419c954f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: file path to the boundary shape file with CSD and Da\n",
    "# Ouput: A dataframe with two columns, one with CSDs and the other with the corresponding DA\n",
    "\n",
    "def get_csd_da_conversion(shape_path):\n",
    "    df_map= gpd.read_file('{}/lda_000a16a_e/lda_000a16a_e.shx'.format(shape_path))\n",
    "    df_map_bc = df_map[df_map['PRNAME'] =='British Columbia / Colombie-Britannique'].reset_index(drop=True)\n",
    "    return_df = df_map_bc[['DAUID', 'CSDUID']]\n",
    "    return return_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "0966a73d-1a7d-4750-9cef-be0401b6cbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_postal_da(pccf_path):\n",
    "    postal_codes = []\n",
    "    dissemination_areas = []\n",
    "    csds = []\n",
    "    quality = []\n",
    "    retired = []\n",
    "    sli = []\n",
    "    rpt = []\n",
    "    dmt = []\n",
    "    \n",
    "    with open(pccf_path, encoding = \"ISO-8859-1\") as file:        \n",
    "        for line in file:\n",
    "            if(line[9:11] == '59'):\n",
    "                postal_codes.append(line[0:6])\n",
    "                dissemination_areas.append(line[125:133])\n",
    "                csds.append(line[15:22])\n",
    "                quality.append(line[212:215])\n",
    "                retired.append(line[203:211])\n",
    "                sli.append(line[161:162])\n",
    "                rpt.append(line[136:137])\n",
    "                dmt.append(line[193:194])\n",
    "                \n",
    "    d = {'postal' : postal_codes, 'da' : dissemination_areas, 'csd' : csds, 'quality' : quality, 'retired' : retired, 'rpt' : rpt, 'dmt' : dmt}  \n",
    "    df1 = pd.DataFrame(data=d) \n",
    "    df2 = df1.drop_duplicates()\n",
    "    df3 = df2[df2.retired == '19000001']\n",
    "    \n",
    "    \n",
    "    return df3[df3.quality == 'BAA']\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b185c0b-f5ce-4ea3-b347-4adf8199adac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a298fd-8d0f-428b-b75b-eae076bb9bdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5341345-b439-43fc-8e1c-4ec3e4ec0a89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51397a34-5637-4307-9b82-accdf60953ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9192fc40-d7ad-49bb-bf51-048d9644edc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "e1525aad-91bc-4654-853a-b61afb2be043",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_postal_da_conversion(pccf_path):\n",
    "    \n",
    "    postal_codes = []\n",
    "    dissemination_areas = []\n",
    "\n",
    "    with open(pccf_path, encoding = \"ISO-8859-1\") as file:\n",
    "        counter = 0\n",
    "        for line in file:\n",
    "            if line[9:11] == '59':\n",
    "                postal = line[0:6]\n",
    "                formatted = \" \".join(line.split())\n",
    "                found = False\n",
    "                start = 1\n",
    "                arr = formatted.split()\n",
    "                while not found and start < len(arr):\n",
    "                    splitted = arr[start]\n",
    "                    # print(splitted)\n",
    "                    if len(splitted) < 35:\n",
    "                        start += 1\n",
    "                    else:\n",
    "                        found = True\n",
    "\n",
    "\n",
    "                da = \"59\" + splitted[len(splitted) - 10:len(splitted)-4]\n",
    "                if counter < 10 and da == '59':\n",
    "                    print(formatted)\n",
    "                    counter += 1\n",
    "\n",
    "                if postal == 'V6A4K3':\n",
    "                    print(formatted)\n",
    "                    print(arr)\n",
    "                    print(splitted)\n",
    "                    print(found)\n",
    "\n",
    "                    # print(splitted[len(splitted)])\n",
    "                if found:\n",
    "                    postal_codes.append(postal)\n",
    "                    dissemination_areas.append(da)\n",
    "    d = {'postal' : postal_codes, 'da' : dissemination_areas}  \n",
    "    df = pd.DataFrame(data=d) \n",
    "    \n",
    "    removed_df = df[~df['postal'].duplicated(keep='first')]\n",
    "    \n",
    "    return removed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "03efd9ca-b5f5-4e4c-814b-f7765abfac01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V6A4K3V6A5959155915022Vancouver CY 02293310058.002099595903509731591531810302 49.288009 -123.09576411VANCOUVER AA20020701190000010BAN14\n",
      "['V6A4K3V6A5959155915022Vancouver', 'CY', '02293310058.002099595903509731591531810302', '49.288009', '-123.09576411VANCOUVER', 'AA20020701190000010BAN14']\n",
      "02293310058.002099595903509731591531810302\n",
      "True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>postal</th>\n",
       "      <th>da</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>V0A0A0</td>\n",
       "      <td>59390219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>V0A1B0</td>\n",
       "      <td>59010123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>V0A1E0</td>\n",
       "      <td>59010124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>V0A1G0</td>\n",
       "      <td>59390216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>V0A1H0</td>\n",
       "      <td>59390219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225706</th>\n",
       "      <td>V9Z1N9</td>\n",
       "      <td>59170657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225708</th>\n",
       "      <td>V9Z1P1</td>\n",
       "      <td>59170668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225710</th>\n",
       "      <td>V9Z1P2</td>\n",
       "      <td>59170668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225711</th>\n",
       "      <td>V9Z1P5</td>\n",
       "      <td>59170664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225712</th>\n",
       "      <td>V9Z2A1</td>\n",
       "      <td>59170652</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>119591 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        postal        da\n",
       "0       V0A0A0  59390219\n",
       "1       V0A1B0  59010123\n",
       "4       V0A1E0  59010124\n",
       "8       V0A1G0  59390216\n",
       "14      V0A1H0  59390219\n",
       "...        ...       ...\n",
       "225706  V9Z1N9  59170657\n",
       "225708  V9Z1P1  59170668\n",
       "225710  V9Z1P2  59170668\n",
       "225711  V9Z1P5  59170664\n",
       "225712  V9Z2A1  59170652\n",
       "\n",
       "[119591 rows x 2 columns]"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_postal_da_conversion(postal_da_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e9be942d-154b-445c-909d-26bcafb5d450",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sa_locations(so_locations_path, so_data_path):\n",
    "    in_dir1 = so_locations_path\n",
    "    in_dir2 = so_data_path\n",
    "\n",
    "    locations = pd.read_csv(in_dir1)\n",
    "    locations=locations.dropna()\n",
    "    data = pd.read_csv(in_dir2)\n",
    "    locations[\"Postal Codes\"] = locations[\"Postal Codes\"].apply(split_fn)\n",
    "    locations = locations.explode(\"Postal Codes\")\n",
    "    locations = locations[locations[\"Postal Codes\"] != \"on Microsoft Teams and Zoom\"]\n",
    "    result = pd.merge(locations, data, how=\"left\", on=[\"Unnamed: 0\"])\n",
    "    result = result.rename(columns={\"Unnamed: 0\": \"Name\"})\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "33aa2f7f-6818-45d2-9f40-e32bcafdd643",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agency_table(bc_ccare_path, so_locations_path, so_data_path, pccf_path, shape_path):\n",
    "    locations = pd.read_csv(bc_ccare_path)\n",
    "    SA_locations = sa_locations(so_locations_path, so_data_path)\n",
    "    \n",
    "    postal = new_postal_da(pccf_path)\n",
    "    # postal = get_postal_da_conversion(pccf_path)\n",
    "    \n",
    "    postal['postal'] = postal['postal'].apply(add_space)\n",
    "    SA_locations['Postal Codes']= SA_locations['Postal Codes'].str.replace('!','1',regex=True)\n",
    "    SA_locations['Postal Codes'] = SA_locations['Postal Codes'].apply(add_space)\n",
    "    SA_locations['Postal Codes'] = SA_locations['Postal Codes'].apply(to_upper)\n",
    "    \n",
    "    new_df = SA_locations.merge(postal, left_on='Postal Codes', right_on='postal')\n",
    "    SA_postal_da = new_df[['postal', 'da', 'Agency Name']]\n",
    "    SA_postal_da = SA_postal_da.rename(columns={'Agency Name' : 'NAME'})\n",
    "    locations_postal_da = locations.merge(postal, left_on='POSTAL_CODE', right_on='postal')[['postal', 'da', 'NAME']]\n",
    "    \n",
    "    combined_postal_da = pd.concat([SA_postal_da, locations_postal_da])\n",
    "    combined_postal_da = combined_postal_da.drop_duplicates()\n",
    "    \n",
    "    csd_da_con = get_csd_da_conversion(shape_path)\n",
    "    csd_da_con['DAUID'] = csd_da_con['DAUID'].astype(str)\n",
    "    csd_info = combined_postal_da.merge(csd_da_con, left_on='da', right_on='DAUID')\n",
    "    \n",
    "    count_csd = csd_info.groupby('CSDUID').count()\n",
    "    counted = csd_info.merge(count_csd['postal'], left_on='CSDUID', right_index = True).rename(columns={'postal_y': \"counts\"})\n",
    "    \n",
    "    counted = counted[['DAUID', 'CSDUID', 'counts']]\n",
    "    return counted.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "a61bda4a-d54b-4be8-ac2b-d8cb6cd26913",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CSDUID</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5915046</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5915022</td>\n",
       "      <td>401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5929011</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5929018</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5915029</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2707</th>\n",
       "      <td>5901048</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2722</th>\n",
       "      <td>5935801</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2730</th>\n",
       "      <td>5917811</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2838</th>\n",
       "      <td>5921014</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2898</th>\n",
       "      <td>5955003</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>152 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       CSDUID  counts\n",
       "0     5915046      90\n",
       "6     5915022     401\n",
       "14    5929011       5\n",
       "19    5929018       2\n",
       "20    5915029      56\n",
       "...       ...     ...\n",
       "2707  5901048       1\n",
       "2722  5935801       1\n",
       "2730  5917811       1\n",
       "2838  5921014       1\n",
       "2898  5955003       1\n",
       "\n",
       "[152 rows x 2 columns]"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agency_table(bc_ccare_path, so_locations_path, so_data_path, postal_da_path, shape_path)[['CSDUID', 'counts']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "9c73f03f-94b8-49ce-9d91-97d096a99bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_supply(agent_table, con_table, agg_type):\n",
    "    scored = agent_table.merge(con_table, how='right', right_on=agg_type, left_on=agg_type)\n",
    "    scored.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    scored = scored.fillna(0)\n",
    "    \n",
    "    # Should we include this part?\n",
    "    if agg_type == 'CSDUID':\n",
    "        scored = scored[['counts', 'CSDUID']]\n",
    "        scored = scored.drop_duplicates()\n",
    "    else:\n",
    "        scored=scored.drop('CSDUID_x', axis=1)\n",
    "        scored = scored.rename(columns={'CSDUID_y' : 'CSDUID'})     \n",
    "    return scored\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3f46f9cc-80fc-4f46-8ffe-7a4e3e0a10c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTES: This is information that needs to be saved in the mega-csv (or a separate csv file)\n",
    "\n",
    "def scale_score_supply(score_table, agg_type, intervals, environics_path):\n",
    "    in_dir1 = environics_path\n",
    "    data = pd.read_csv(in_dir1)\n",
    "    \n",
    "    if agg_type == 'DAUID':\n",
    "        data = data[data.GEO == 'PRCDDA']\n",
    "    else:\n",
    "        data = data[data.GEO == 'PRCDCSD']\n",
    "    \n",
    "    data['CODE']=data['CODE'].astype(int)\n",
    "    score_table[agg_type]=score_table[agg_type].astype(int)\n",
    "    score_table = score_table[[agg_type, 'counts']]\n",
    "        \n",
    "    data = data.merge(score_table, left_on='CODE', right_on=agg_type)\n",
    "    # data['scaled'] = data['counts'] / data['ECYPTA_5_9']\n",
    "    data['scaled'] = data['counts'] / (data['ECYPTA_5_9'] + data['ECYPTA1014'])\n",
    "    data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    data = data.fillna(0)\n",
    "    \n",
    "    \n",
    "    data = data[[agg_type, 'counts', 'scaled']]\n",
    "    \n",
    "    n = intervals\n",
    "    meta_data = {}\n",
    "    meta_data['scaled'] = (data['scaled'].max() - data['scaled'].min()) / n\n",
    "    data['score_scaled'] = 0\n",
    "    for i in range(n):\n",
    "        data['score_scaled'][data['scaled'].between(meta_data.get('scaled') * i, meta_data.get('scaled') * (i + 1))] = (i+1)\n",
    "    \n",
    "    data['score_scaled'] /= 10\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e794c175-4f57-465b-9a9a-8d2d872ad28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTES: This is information that needs to be saved in the mega-csv (or a separate csv file)\n",
    "\n",
    "def total_scores(supply, demand, agg_type, with_supply):\n",
    "    supply[agg_type] = supply[agg_type].astype(int)\n",
    "    demand['CODE'] = demand['CODE'].astype(int)\n",
    "    full_data = demand.merge(supply, left_on='CODE', right_on=agg_type)\n",
    "    if with_supply:\n",
    "        full_data['diff'] = full_data['score_scaled'] - full_data['total']\n",
    "    else:\n",
    "        full_data['diff'] = 1 - full_data['total']\n",
    "    \n",
    "    return full_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "330cc104-7703-4bce-af6a-4fe67a07be6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_map(total_scores, agg_type, shape_path, col_name):\n",
    "    if agg_type == 'CSDUID':\n",
    "        mp = gpd.read_file('{}/lcsd000a16a_e/lcsd000a16a_e.shx'.format(shape_path))\n",
    "    else:\n",
    "        mp = gpd.read_file('{}/lda_000a16a_e/lda_000a16a_e.shx'.format(shape_path))\n",
    "    mp = mp[mp['PRNAME'] =='British Columbia / Colombie-Britannique'].reset_index(drop=True)\n",
    "    \n",
    "    # mp = mp[mp['CDUID'] == '5909']\n",
    "    \n",
    "    # mp = mp.merge(total_scores, left_on='CSDUID', right_index = True)\n",
    "    scores = total_scores[[col_name]]\n",
    "    mp['scores'] = scores\n",
    "    print(mp)\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(20,20))\n",
    "    mp.plot(column='scores', ax=ax, legend=True, cmap='OrRd')\n",
    "    # plt.savefig('bc.png')\n",
    "    # df_map5.show()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "deb91ed0-0b49-4d30-b5c7-4ee985b09350",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x, maximum, minimum):\n",
    "    return 1 - ((x - minimum) / (maximum - minimum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bb2318ef-4603-4cd1-a43c-eded71550c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(args):\n",
    "    \n",
    "    # Here is where we can change the variables and the weights\n",
    "    \n",
    "    if args == 'DA':\n",
    "    \n",
    "        weights = [0.2, 0.2, 0.2, 0.16, 0.12, 0.12]\n",
    "        # weights = [1, 1, 1, 1, 1, 1]\n",
    "        forced_choices = ['vis_minority_blk', 'house_pop_abrgnl', 'total_recent_immigrant', 'median_income', 'lone_parent', 'total_kids']\n",
    "    else:\n",
    "        \n",
    "        # 0.13 * household_recent_immigrant, 0.13 * vis_minority_blk, 0.13 * abrgnl_id, \n",
    "        # 0.125 * no_off_lang, 0.125 * low_income, 0.125 * median_income, 0.1175 * lone_parent, \n",
    "        # 0.1175 * kids_home_5_9 \n",
    "        # weights = [1, 1, 1, 1, 1, 1, 1, 1]\n",
    "        \n",
    "        # Paper submission version\n",
    "        # weights = [0.13, 0.13, 0.13, 0.125, 0.125, 0.125, 0.1175, 0.1175]\n",
    "        # forced_choices = ['household_recent_immigrant', 'vis_minority_blk', 'abrgnl_id', 'no_off_lang', 'low_income', 'median_income', 'lone_parent', 'total_kids_home']\n",
    "        # Pronounced Weights Indigenous communities:\n",
    "        weights = [0.05, 0.05, 0.2, 0.1, 0.175, 0.1, 0.175, 0.15]\n",
    "        forced_choices = ['household_recent_immigrant', 'vis_minority_blk', 'abrgnl_id', 'no_off_lang', 'low_income', 'median_income', 'lone_parent', 'total_kids_home']\n",
    "        \n",
    "\n",
    "        # Without kids 10-14\n",
    "        # forced_choices = ['household_recent_immigrant', 'vis_minority_blk', 'abrgnl_id', 'no_off_lang', \n",
    "        # 'low_income', 'median_income', 'lone_parent', 'kids_home_5_9'] \n",
    "        \n",
    "        # Without poverty statistics\n",
    "        # weights = [0.2, 0.2, 0.2, 0.16, 0.12, 0.12]\n",
    "        # forced_choices = ['household_recent_immigrant', 'vis_minority_blk', 'abrgnl_id', 'no_off_lang', 'lone_parent', 'total_kids_home']\n",
    "\n",
    "        # Without aboriginal community \n",
    "        # weights = [0.195, 0.195, 0.125, 0.125, 0.125, 0.1175, 0.1175]\n",
    "        # forced_choices = ['household_recent_immigrant', 'vis_minority_blk', 'no_off_lang', 'low_income', 'median_income', 'lone_parent', 'total_kids_home']\n",
    "        \n",
    "        # With kids 10-14\n",
    "        # forced_choices = ['household_recent_immigrant', 'abrgnl_id', 'vis_minority_blk', 'no_off_lang', 'median_income', 'low_income', 'lone_parent', 'total_kids_home']\n",
    "\n",
    "        \n",
    "    \n",
    "    bc_ccare_path = '402DATA/childcare_locations.csv'\n",
    "    environics_path = \"402DATA/SFU_CommunityImpactSO/EnvironicsData/DemoStats_2020_SelectVarsData.csv\"\n",
    "    so_locations_path = \"402DATA/SFU_CommunityImpactSO/SchoolsOutData/SO_map.csv\"\n",
    "    so_data_path = \"402DATA/SFU_CommunityImpactSO/SchoolsOutData/SO_DirectMetrics.csv\"\n",
    "    pccf_path = '402DATA/dataverse_files/Data/pccfNat_fccpNat_082021.txt'\n",
    "    shape_path = '402DATA/SFU_CommunityImpactSO/GeoData/BoundaryShapeFiles'\n",
    "    \n",
    "    interval_num = 10\n",
    "    num_vars = len(weights)\n",
    "    \n",
    "    if args == 'DA':\n",
    "        pr_code = 'PRCDDA'\n",
    "        agg_type = 'DAUID'\n",
    "    elif args == 'CSD':\n",
    "        pr_code = 'PRCDCSD'\n",
    "        agg_type = 'CSDUID'\n",
    "        \n",
    "    df1 = pd.read_csv(environics_path)\n",
    "\n",
    "    \n",
    "    drop_list = [total_area, total_land_area, total_60_64, total_65_69, total_70_74, total_75_79, \n",
    "                 total_80_84, total_85_plus, total_65_alone, house_pop_5_year_mobility,  movers, \n",
    "                 household_tenure, rented, band_housing, total_condo_status, in_condo, rented_in_condo, \n",
    "                 income_40_59, income_60_79, income_80_100, fifteen_older_income, without_income, \n",
    "                 kids_home_10_14, total_10_14, lp_one_child, lp_two_child, lp_three_more_child]\n",
    "    \n",
    "    df = rename(scale_and_drop(get_rows(df1, pr_code), drop_list))\n",
    "    df_choice = df[['CODE'] + forced_choices]\n",
    "    \n",
    "    demand = create_score_table(df_choice, num_vars, interval_num, weights)\n",
    "    \n",
    "    print(demand.sort_values(by='total').head(20))\n",
    "    print()\n",
    "    \n",
    "    counted = agency_table(bc_ccare_path, so_locations_path, so_data_path, pccf_path, shape_path)\n",
    "    csd_da = get_csd_da_conversion(shape_path)\n",
    "    score_table = score_supply(counted, csd_da, agg_type)\n",
    "    supply = scale_score_supply(score_table, agg_type, interval_num, environics_path)\n",
    "    \n",
    "    with_supply = True\n",
    "    totals = total_scores(supply, demand, agg_type, with_supply)\n",
    "    \n",
    "    minimum = totals['diff'].min()\n",
    "    maximum = totals['diff'].max()\n",
    "    totals['diff'] = totals['diff'].apply(normalize, args=(maximum, minimum,))\n",
    "    \n",
    "    \n",
    "    # totals['total'][totals['total_kids_home'] == 0] = 0\n",
    "    \n",
    "#     totals['CODE'] = totals['CODE'].astype(int)\n",
    "#     csd_da['DAUID'] = csd_da['DAUID'].astype(int)\n",
    "    \n",
    "#     totals['diff'][totals['diff'] >= 0.90] = 1\n",
    "\n",
    "    \n",
    "#     totals = totals.merge(csd_da, left_on='CODE', right_on='DAUID')\n",
    "#     totals = totals[['diff', 'CSDUID', 'total_kids']]\n",
    "#     totals = totals.groupby('CSDUID').median()\n",
    "    \n",
    "    totals['diff'][totals['total_kids_home'] == 0] = 0\n",
    "    print(totals)\n",
    "    display_map(totals, 'CSDUID', shape_path, 'diff')\n",
    "\n",
    "    \n",
    "    print(\"printing diff\")\n",
    "\n",
    "    sorted_totals = totals.sort_values(by='diff', ascending=False)\n",
    "    print(sorted_totals[['diff', 'CSDUID']].head(20))\n",
    "    # print(sorted_totals[sorted_totals['diff'] == 1])\n",
    "    \n",
    "    # print(\"printing totals\")\n",
    "    # sorted_totals = totals.sort_values(by='total', ascending=False)\n",
    "    # print(sorted_totals.head(20))\n",
    "    \n",
    "    return sorted_totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "aed58681-2aca-4fde-8c26-f2f3c0b4c513",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '402DATA/SFU_CommunityImpactSO/EnvironicsData/DemoStats_2020_SelectVarsData.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/5_/p_vl5dl52y528jsmc1hmw3sm0000gn/T/ipykernel_29266/3584618805.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtotals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'CSD'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/5_/p_vl5dl52y528jsmc1hmw3sm0000gn/T/ipykernel_29266/3659092367.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0magg_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'CSDUID'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     \u001b[0mdf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menvironics_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \"\"\"\n\u001b[0;32m--> 222\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '402DATA/SFU_CommunityImpactSO/EnvironicsData/DemoStats_2020_SelectVarsData.csv'"
     ]
    }
   ],
   "source": [
    "totals = main('CSD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f78796-3d88-4a18-9d5c-45c5706ac32f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
