{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "5b738592-06c1-4816-98d7-dc704193f49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This project was created by Eshaank Joshi, Tarunjeev Junja, Trevor Noble, and Evan Vulliamy\n",
    "# The purpose of this project is to assist United Way\n",
    "# in the location of areas in need of after school programs in British Columbia.\n",
    "# The code first selects the rows of the Environics data that correspond to the desired geographical \n",
    "# regions and province.\n",
    "# Next, the data is scaled by relevant population sizes to allow for comparison between different geographical regions.\n",
    "# The scaled data is then clustered based on correlation scores between each variables. \n",
    "# Only one variable is to be selected from each cluster.\n",
    "# Once the variables are selected then a score for demand is produced by grouping the data \n",
    "# into deciles and weights are applied.\n",
    "# Another score is produced for the amount of supply in each region which is based on the number of available \n",
    "# childcare services in each region.\n",
    "# The difference is taken between supply and demand to quantify the amount of need.\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "import os\n",
    "import seaborn as sns\n",
    "import scipy.cluster.hierarchy as spc\n",
    "import pandas_bokeh\n",
    "import pyproj\n",
    "import geopandas as gpd\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from collections import Counter\n",
    "from scipy import stats\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432e5672-82e7-4434-acab-9cabac746df2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "f14ba7b2-a0fc-4e1c-ae9a-68c534ded621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGE THESE TO YOUR PATHS\n",
    "\n",
    "bc_ccare_path = \"~/Desktop/code/Math402W/402DATA/childcare_locations.csv\"\n",
    "environics_path = \"~/Desktop/code/Math402W/402DATA/SFU_CommunityImpactSO/EnvironicsData/DemoStats_2020_SelectVarsData.csv\"\n",
    "so_locations_path = \"~/Desktop/code/Math402W/402DATA/SFU_CommunityImpactSO/SchoolsOutData/SO_map.csv\"\n",
    "so_data_path = \"~/Desktop/code/Math402W/402DATA/SFU_CommunityImpactSO/SchoolsOutData/SO_DirectMetrics.csv\"\n",
    "shape_path = \"~/Desktop/code/Math402W/402DATA/SFU_CommunityImpactSO/GeoData/BoundaryShapeFiles\"\n",
    "postal_da_path = r\"/Users/evanvulliamy/Desktop/code/Math402W/402DATA/dataverse_files/Data/pccfNat_fccpNat_082021.txt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "id": "90be20f1-53cb-41dd-a41d-16d09aea2c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataframes based on the paths\n",
    "\n",
    "bc_ccare_df = pd.read_csv(bc_ccare_path)\n",
    "environics_df = pd.read_csv(environics_path)\n",
    "so_locations_df = pd.read_csv(so_locations_path)\n",
    "so_data_df = pd.read_csv(so_data_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7210ee-1638-486d-aa00-09b968b28840",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "id": "78d40184-4871-42f0-b63e-65d2b3b772f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the first two digits of the area code which corresponds to the province\n",
    "def get_province(val):\n",
    "    return str(val)[0:2]\n",
    "\n",
    "# Returns the second to fourth digits which corresponds to the census area\n",
    "def get_census_area(val):\n",
    "    return str(val)[2:4]\n",
    "\n",
    "# Adds a space to format postal codes xxxxxx -> xxx xxx\n",
    "def add_space(string):\n",
    "    if len(string) >= 7:\n",
    "        return string\n",
    "    return string[0:3] + \" \" + string[3:6]\n",
    "\n",
    "# Raise all characters to upper case\n",
    "def to_upper(string):\n",
    "    return string.upper()\n",
    "\n",
    "# Separate a string by commas\n",
    "def split_fn(string):\n",
    "    return string.split(',')\n",
    "\n",
    "# Returns the last word in a sentence\n",
    "def get_last_word(val):\n",
    "    arr = val.split(\" \")\n",
    "    return arr[-1].isnumeric()\n",
    "\n",
    "# Returns x normalized in the [0, 1] range where inputs scores get higher outputs\n",
    "def normalize(x, maximum, minimum):\n",
    "    return 1 - ((x - minimum) / (maximum - minimum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "id": "a2870bec-99a5-491d-b75f-8186cdfd0f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables\n",
    "\n",
    "total_area = \"ECYASQKM\" # DROP\n",
    "total_land_area = \"ECYALSQKM\" # DROP \n",
    "total_pop_1 = \"ECYBASPOP\" # SCALAR\n",
    "total_pop_2 = \"ECYPTAPOP\" # SCALAR\n",
    "total_5_9 = \"ECYPTA_5_9\" # NEEDS SCALING total_pop_1\n",
    "total_10_14 = \"ECYPTA1014\" # DROP\n",
    "total_60_64 = \"ECYPTA6064\" # DROP\n",
    "total_65_69 = \"ECYPTA6569\" # DROP\n",
    "total_70_74 = \"ECYPTA7074\" # DROP\n",
    "total_75_79 = \"ECYPTA7579\" # DROP\n",
    "total_80_84 = \"ECYPTA8084\" # DROP\n",
    "total_85_plus = \"ECYPTA85P\" # DROP\n",
    "total_fam_households = \"ECYHTYFHT\" # SCALAR <- should we use this one over census families??\n",
    "total_65_alone = \"ECYHTYN65A\" # DROP\n",
    "\n",
    "census_families = \"ECYCFSCF\" # SCALAR\n",
    "cf_with_children = \"ECYCFSCWC\" # NEEDS SCALING census_families\n",
    "lone_parent = \"ECYCFSLP\" # NEEDS SCALING census_families\n",
    "lp_one_child = \"ECYCFSLP1C\" # NEEDS SCALING census_families\n",
    "lp_two_child = \"ECYCFSLP2C\" # NEEDS SCALING census_families\n",
    "lp_three_more_child = \"ECYCFSLP3C\" # NEEDS SCALING census_families\n",
    "percent_children_home = \"ECYHFSWC\" # KEEP AS IS\n",
    "total_kids_home = \"ECYCHAKIDS\" # SCALAR\n",
    "kids_home_5_9 = \"ECYCHA_5_9\" # NEEDS SCALING total_kids_home\n",
    "kids_home_10_14 = \"ECYCHA1014\" # DROP\n",
    "avg_child_per_fam = \"ECYCHACFCH\" # KEEP AS IS\n",
    "\n",
    "\n",
    "house_pop_5_year_mobility = \"ECYMOBHPOP\" # DROP\n",
    "movers = \"ECYMOBMOV\" # DROP\n",
    "household_tenure = \"ECYTENHHD\" # DROP\n",
    "rented = \"ECYTENRENT\" # DROP\n",
    "band_housing = \"ECYTENBAND\" # DROP\n",
    "total_condo_status = \"ECYCDOHHD\" # DROP\n",
    "in_condo = \"ECYCDOCO\" # DROP\n",
    "rented_in_condo = \"ECYCDORECO\" # DROP\n",
    "\n",
    "total_households = \"ECYHNIHHD\" # SCALAR\n",
    "income_0_19 = \"ECYHNI_020\" # ADD WITH income_20_39 NEEDS SCALING total_households\n",
    "income_20_39 = \"ECYHNI2040\" # ADD WITH income income_0_19 NEEDS SCALING total_households\n",
    "income_40_59 = \"ECYHNI4060\" # DROP \n",
    "income_60_79 = \"ECYHNI6080\" # DROP\n",
    "income_80_100 = \"ECYHNIX100\" # DROP \n",
    "median_income = \"ECYHNIMED\" # KEEP AS IS\n",
    "fifteen_older_income = \"ECYPNIHP15\" # DROP\n",
    "without_income = \"ECYPNININ\" # DROP <- FOR NOW, might decide against this\n",
    "avg_income = \"ECYPNIAVG\" # KEEP AS IS\n",
    "unemployment_rate = \"ECYACTUR\" # KEEP AS IS\n",
    "travel_to_work = \"ECYTRAHPL\" # SCALAR\n",
    "travel_to_work_transit = \"ECYTRAPUBL\" # NEEDS SCALING travel_to_work\n",
    "house_pop_vis_minority = \"ECYVISHPOP\" # SCALAR\n",
    "vis_minority_total = \"ECYVISVM\" # SCALAR\n",
    "vis_minority_blk = \"ECYVISBLCK\" # NEEDS SCALING vis_minority_total\n",
    "house_pop_abrgnl = \"ECYAIDHPOP\" # NEEDS SCALING total_households\n",
    "abrgnl_id = \"ECYAIDABO\" # NEEDS SCALING vis_minority_total\n",
    "pop_knowledge_off_lang = \"ECYKNOHPOP\" # SCAlAR\n",
    "no_off_lang = \"ECYKNONEF\" # NEEDS SCALING pop_knowledge_off_lang\n",
    "household_recent_immigrant = \"ECYRIMHPOP\" # NEEDS SCALING total_households\n",
    "total_recent_immigrant = \"ECYRIMRIM\" # NEEDS SCALING total_pop_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "1317acd2-feab-458b-a2d7-eb30d9ab1a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT: \n",
    "# df: a dataframe of Environics data or Shapefile data\n",
    "# area: Either PRCDDA (dissemination areas) or PRCDCSD (census subdivisions)\n",
    "# OUTPUT:\n",
    "# A dataframe consisting of only rows belonging to BC and either DA or CSDs\n",
    "\n",
    "def get_rows(df, area):\n",
    "    return_df = df.loc[df.GEO == area]\n",
    "    new_df = return_df.copy()\n",
    "    new_df['prov'] = new_df['CODE'].apply(get_province)\n",
    "    new_df = new_df[new_df.prov == \"59\"]\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "8f9ec392-1d30-4d2a-89ad-b292a15dfd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSD = get_rows(environics_df, \"PRCDCSD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d2e216-e267-4934-ac58-4a43f96092f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "c390d01c-893b-4b06-9a51-f61e587b34a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT:\n",
    "# df: A dataframe of environics data (environics_df)\n",
    "# drop_list: a list of all variables that do not need to be considered\n",
    "# OUTPUT:\n",
    "# An environics dataframe of variables scaled by relevant populations\n",
    "\n",
    "# IDEAS: Change low income to be based on distance from median income?\n",
    "\n",
    "# NOTES: This is information that needs to be saved in the mega-csv (or a separate csv file)\n",
    "\n",
    "def scale_and_drop(df, drop_list):\n",
    "    scaled_df = df.copy()\n",
    "    scaled_df['unscaled_5_9'] = df[total_5_9]\n",
    "    scaled_df[total_5_9] = df[total_5_9] / df[total_pop_1]\n",
    "    scaled_df[lone_parent] =  df[lone_parent] / df[census_families]\n",
    "    scaled_df[kids_home_5_9] =  df[kids_home_5_9] / df[total_kids_home]\n",
    "    scaled_df['low_income'] =  (df[income_0_19] + df[income_20_39]) / df[total_households]\n",
    "    scaled_df[travel_to_work_transit] =  df[travel_to_work_transit] / df[travel_to_work]\n",
    "    scaled_df[vis_minority_blk] =  df[vis_minority_blk] / df[vis_minority_total]\n",
    "    scaled_df[house_pop_abrgnl] =  df[house_pop_abrgnl] / df[total_households]\n",
    "    scaled_df[abrgnl_id] =  df[abrgnl_id] / df[vis_minority_total]\n",
    "    scaled_df[no_off_lang] =  df[no_off_lang] / df[pop_knowledge_off_lang]\n",
    "    scaled_df[household_recent_immigrant] =  df[household_recent_immigrant] / df[total_households]\n",
    "    scaled_df[total_recent_immigrant] =  df[total_recent_immigrant] / df[total_pop_1]\n",
    "    \n",
    "    # Drop scalars\n",
    "    # scaled_df = scaled_df.drop([total_pop_1, total_pop_2, total_fam_households, census_families, total_kids_home,\n",
    "    #                             total_households, travel_to_work, house_pop_vis_minority,\n",
    "    #                              vis_minority_total, pop_knowledge_off_lang, income_0_19, income_20_39, 'prov', 'GEO'], axis = 1)\n",
    "    scaled_df = scaled_df.drop(['prov', 'GEO', income_0_19, income_20_39], axis = 1)\n",
    "    # Drop extra cols\n",
    "    scaled_df = scaled_df.drop(drop_list, axis = 1)\n",
    "    \n",
    "    # Reformat cells that are inf after dividing by zero\n",
    "    scaled_df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    scaled_df = scaled_df.fillna(0)\n",
    "    scaled_df = rename(scaled_df)\n",
    "    \n",
    "    return scaled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "0a8a4ce5-576a-4a54-933b-36ab1cd20557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: an environics dataframe\n",
    "# Output: a dataframe with renamed columns \n",
    "# Used in scale_and_drop\n",
    "def rename(df):\n",
    "    df = df.rename(columns={total_5_9 : \"total_5_9\", total_10_14 : \"total_10_14\", cf_with_children : \"cf_with_children\", lone_parent : \"lone_parent\",\n",
    "                  lp_one_child : \"lp_one_child\", lp_two_child : \"lp_two_child\", lp_three_more_child : \"lp_three_more_child\", kids_home_5_9 : \"total_kids_home\",\n",
    "                  kids_home_10_14 : \"total_kids_home\", travel_to_work_transit : \"travel_to_work_transit\", vis_minority_blk : \"vis_minority_blk\",\n",
    "                  house_pop_abrgnl : \"house_pop_abrgnl\", abrgnl_id : \"abrgnl_id\", no_off_lang : \"no_off_lang\", household_recent_immigrant : \"household_recent_immigrant\",\n",
    "                  total_recent_immigrant : \"total_recent_immigrant\", percent_children_home : \"percent_children_home\", avg_child_per_fam : \"avg_child_per_fam\",\n",
    "                  median_income : \"median_income\", avg_income : \"avg_income\", unemployment_rate : \"unemployment_rate\", total_pop_1 : \"total_pop_1_SCALAR\", total_pop_2 : \"total_pop_2_SCALAR\",\n",
    "                  total_fam_households : \"total_fam_households_SCALAR\", census_families : \"census_families_SCALAR\", total_kids_home : \"total_kids_home_SCALAR\", total_households : \"total_households_SCALAR\",\n",
    "                  travel_to_work : \"travel_to_work_SCALAR\", house_pop_vis_minority : \"house_pop_vis_minority_SCALAR\", vis_minority_total : \"vis_minority_total_SCALAR\", \n",
    "                  pop_knowledge_off_lang : \"pop_knowledge_off_lang_SCALAR\", })\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3333e746-bb3a-47da-961f-9c177cf500b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "a26d4f62-2fd6-4201-9e15-32697feb5e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: a dataframe that has been run through \"scale and drop\"\n",
    "# Output: a 2d matrix representing the correlation of each variable with one another\n",
    "\n",
    "def correlation(df):\n",
    "    \n",
    "    temp_df = df.copy()\n",
    "    temp_df = temp_df.drop(['CODE'], axis=1)\n",
    "    \n",
    "    column_names = temp_df.columns\n",
    "    print(column_names)\n",
    "    \n",
    "    values_scaled = []\n",
    "\n",
    "    for var_i in column_names:\n",
    "        if var_i == 'CODE':\n",
    "            continue\n",
    "        for var_j in column_names:\n",
    "            if var_j == 'CODE':\n",
    "                continue\n",
    "            correlation_coef = stats.linregress(temp_df[var_i], temp_df[var_j]).rvalue\n",
    "            values_scaled.append(correlation_coef)\n",
    "    \n",
    "    dims = len(column_names)\n",
    "    \n",
    "    values_scaled = np.array(values_scaled)\n",
    "    values_scaled = values_scaled.reshape(dims,dims)\n",
    "    plot_df = pd.DataFrame(data = values_scaled, columns = column_names, index = column_names)\n",
    "    \n",
    "    plt.rcParams[\"figure.figsize\"] = (30,20)\n",
    "    plt.title(\"Correlation Coefficient\", fontsize=20)\n",
    "    sns.heatmap(plot_df, annot = True)\n",
    "    plt.xticks(rotation=45, fontsize = 15)\n",
    "    plt.yticks(fontsize = 10)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "06e60724-1d73-47ac-9eb5-19397184f561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: a dataframe that has been run through \"scale and drop\"\n",
    "# Output: The table of correlated clusters, and the related dendrogram\n",
    "\n",
    "# NOTES: This is information that needs to be saved in the mega-csv (or a separate csv file)\n",
    "\n",
    "def display_cor_clusters(df):\n",
    "    \n",
    "    # Code referenced from:\n",
    "    # https://stackoverflow.com/questions/52787431/create-clusters-using-correlation-matrix-in-python\n",
    "    cols = []\n",
    "    df_scaled = df.drop(['CODE'], axis=1)\n",
    "    for elems in df_scaled.columns:\n",
    "        if elems[-6:] != 'SCALAR':\n",
    "            cols.append(elems)\n",
    "    \n",
    "    df_scaled = df_scaled[cols]\n",
    "    corr = df_scaled.corr().values\n",
    "    \n",
    "    pdist = spc.distance.pdist(corr)\n",
    "    linkage = spc.linkage(pdist, method='complete')\n",
    "    idx_scaled = spc.fcluster(linkage, 0.5 * pdist.max(), 'distance')\n",
    "    plt.figure(figsize=(20,40))\n",
    "    \n",
    "    dn = spc.dendrogram(linkage)\n",
    "    spc.set_link_color_palette(['m', 'c', 'y', 'k'])\n",
    "    # fig, axes = plt.subplots(1, 2, figsize=(8, 3))\n",
    "    # dn1 = spc.dendrogram(dn, ax=axes[0], above_threshold_color='y',\n",
    "    #                            orientation='top')\n",
    "    # dn2 = spc.dendrogram(dn, ax=axes[1],\n",
    "    #                            above_threshold_color='#bcbddc',\n",
    "    #                            orientation='right')\n",
    "    spc.set_link_color_palette(None)  # reset to default after use\n",
    "    plt.show()\n",
    "    \n",
    "    # print(pdist, linkage, idx_scaled)\n",
    "    scaled_cols = {\"var\" : df_scaled.columns, \"cluster\" : idx_scaled}\n",
    "    df_scaled = pd.DataFrame(data=scaled_cols)\n",
    "    sorted_scaled = df_scaled.sort_values(by='cluster')\n",
    "    print(sorted_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "f0fcfb4d-7e85-440a-b1a9-f6c216c96690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: \n",
    "# df: a scaled df, with columns [CODE, chosen_var_1, chosen_var_2, ... , chosen_var_n]\n",
    "# num_intervals: the number of intervals to divide the data into (in our project we used 10)\n",
    "# weights: a list of n weights for each of the variables \n",
    "\n",
    "# Output: \n",
    "# a dataframe with the original variables and the scores produced for each variable\n",
    "\n",
    "# NOTES: This is information that needs to be saved in the mega-csv (or a separate csv file)\n",
    "\n",
    "def create_score_table(df, num_intervals, weights):\n",
    "    # This is some code for the scoring process\n",
    "    # It creates a new dataframe for the scores of each variable\n",
    "    # n is the number of itervals\n",
    "    # num_vars is the number of variables used\n",
    "    n = num_intervals\n",
    "    num_vars = len(weights)\n",
    "    meta_data = {}\n",
    "    \n",
    "    # calculate the interval size (max - min) / n\n",
    "    for col in df.columns:\n",
    "        if col == 'CODE':\n",
    "            continue\n",
    "        meta_data[col] = (df[col].max() - df[col].min()) / n\n",
    "\n",
    "    # Create the score table\n",
    "    score_df = df[['CODE']]\n",
    "    score_list = []\n",
    "    for keys in meta_data.keys():\n",
    "        score_list.append('weighted_{}'.format(keys))\n",
    "    score_df[score_list] = 0\n",
    "    \n",
    "    \n",
    "    # iterate through and score each variable\n",
    "    scoring = score_df.copy()\n",
    "    for index, col in enumerate(df.columns):\n",
    "        for i in range(n):\n",
    "            if col == 'CODE':\n",
    "                continue    \n",
    "            if col != 'avg_income' and col != 'median_income':\n",
    "                # Higher values mean higher scores\n",
    "                scoring.loc[df[col].between(meta_data.get(col) * i, meta_data.get(col) * (i + 1)), \n",
    "                            ['weighted_{}'.format(col)]] = (i+1)\n",
    "            else:\n",
    "                # Higher values mean lower scores\n",
    "                scoring.loc[df[col].between(meta_data.get(col) * i, meta_data.get(col) * (i + 1)), \n",
    "                            ['weighted_{}'.format(col)]] = num_intervals - i\n",
    "                \n",
    "    pre_scale = scoring[['weighted_{}'.format(keys) for keys in meta_data.keys()]].copy()\n",
    "    pre_scale = pre_scale.set_axis(['unscaled_score_{}'.format(keys) for keys in meta_data.keys()], axis='columns', inplace=False)\n",
    "    pre_scale['CODE'] = df['CODE']\n",
    "    \n",
    "    scoring = weights * scoring[['weighted_{}'.format(keys) for keys in meta_data.keys()]]\n",
    "    scoring['total'] = scoring.sum(axis = 1)\n",
    "    scoring['percent_total'] = scoring['total'] / num_intervals\n",
    "    scoring['CODE'] = df['CODE']\n",
    "    # return_df = scoring.merge(df, left_on='CODE', right_on='CODE')\n",
    "    return_df = scoring.merge(pre_scale, left_on='CODE', right_on='CODE')\n",
    "    return_df = return_df.sort_values(by='total', ascending=False)\n",
    "    return return_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "1a3e9ec6-cdad-40a2-bc86-45e79eba39b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_list = [total_area, total_land_area, total_60_64, total_65_69, total_70_74, total_75_79, \n",
    " total_80_84, total_85_plus, total_65_alone, house_pop_5_year_mobility,  movers, \n",
    " household_tenure, rented, band_housing, total_condo_status, in_condo, rented_in_condo, \n",
    " income_40_59, income_60_79, income_80_100, fifteen_older_income, without_income, \n",
    " kids_home_10_14, total_10_14, lp_one_child, lp_two_child, lp_three_more_child, cf_with_children]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad5fd79-61fe-450c-8463-d4d6e0fb51ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "9d19ca8c-8d98-4538-9958-1834fb6d55d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df_csd = scale_and_drop(CSD, drop_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "7dacec08-7224-4227-a154-a527ea5e04a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CODE</th>\n",
       "      <th>total_pop_1_SCALAR</th>\n",
       "      <th>total_pop_2_SCALAR</th>\n",
       "      <th>total_5_9</th>\n",
       "      <th>total_fam_households_SCALAR</th>\n",
       "      <th>census_families_SCALAR</th>\n",
       "      <th>lone_parent</th>\n",
       "      <th>percent_children_home</th>\n",
       "      <th>total_kids_home_SCALAR</th>\n",
       "      <th>total_kids_home</th>\n",
       "      <th>...</th>\n",
       "      <th>vis_minority_total_SCALAR</th>\n",
       "      <th>vis_minority_blk</th>\n",
       "      <th>house_pop_abrgnl</th>\n",
       "      <th>abrgnl_id</th>\n",
       "      <th>pop_knowledge_off_lang_SCALAR</th>\n",
       "      <th>no_off_lang</th>\n",
       "      <th>household_recent_immigrant</th>\n",
       "      <th>total_recent_immigrant</th>\n",
       "      <th>unscaled_5_9</th>\n",
       "      <th>low_income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29477</th>\n",
       "      <td>5943816.0</td>\n",
       "      <td>237</td>\n",
       "      <td>237</td>\n",
       "      <td>0.071730</td>\n",
       "      <td>55</td>\n",
       "      <td>59</td>\n",
       "      <td>0.152542</td>\n",
       "      <td>56</td>\n",
       "      <td>80</td>\n",
       "      <td>0.212500</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.246575</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>237</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.246575</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17</td>\n",
       "      <td>0.328767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29537</th>\n",
       "      <td>5943817.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29597</th>\n",
       "      <td>5943835.0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29657</th>\n",
       "      <td>5943836.0</td>\n",
       "      <td>73</td>\n",
       "      <td>73</td>\n",
       "      <td>0.068493</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29717</th>\n",
       "      <td>5943837.0</td>\n",
       "      <td>461</td>\n",
       "      <td>461</td>\n",
       "      <td>0.047722</td>\n",
       "      <td>146</td>\n",
       "      <td>146</td>\n",
       "      <td>0.328767</td>\n",
       "      <td>33</td>\n",
       "      <td>162</td>\n",
       "      <td>0.135802</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.822581</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>452</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.822581</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22</td>\n",
       "      <td>0.645161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72557</th>\n",
       "      <td>5915015.0</td>\n",
       "      <td>216320</td>\n",
       "      <td>216320</td>\n",
       "      <td>0.041841</td>\n",
       "      <td>57981</td>\n",
       "      <td>62174</td>\n",
       "      <td>0.165873</td>\n",
       "      <td>48</td>\n",
       "      <td>65889</td>\n",
       "      <td>0.131904</td>\n",
       "      <td>...</td>\n",
       "      <td>170221</td>\n",
       "      <td>0.009447</td>\n",
       "      <td>2.708127</td>\n",
       "      <td>0.011597</td>\n",
       "      <td>214443</td>\n",
       "      <td>0.111176</td>\n",
       "      <td>2.708127</td>\n",
       "      <td>0.061035</td>\n",
       "      <td>9051</td>\n",
       "      <td>0.257776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72588</th>\n",
       "      <td>5915020.0</td>\n",
       "      <td>19383</td>\n",
       "      <td>19383</td>\n",
       "      <td>0.045194</td>\n",
       "      <td>4156</td>\n",
       "      <td>4252</td>\n",
       "      <td>0.200611</td>\n",
       "      <td>42</td>\n",
       "      <td>4677</td>\n",
       "      <td>0.177892</td>\n",
       "      <td>...</td>\n",
       "      <td>12352</td>\n",
       "      <td>0.006477</td>\n",
       "      <td>2.526659</td>\n",
       "      <td>0.025502</td>\n",
       "      <td>17439</td>\n",
       "      <td>0.063249</td>\n",
       "      <td>2.526659</td>\n",
       "      <td>0.038745</td>\n",
       "      <td>876</td>\n",
       "      <td>0.393799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72619</th>\n",
       "      <td>5915022.0</td>\n",
       "      <td>682404</td>\n",
       "      <td>682404</td>\n",
       "      <td>0.033958</td>\n",
       "      <td>162731</td>\n",
       "      <td>171041</td>\n",
       "      <td>0.157477</td>\n",
       "      <td>29</td>\n",
       "      <td>153585</td>\n",
       "      <td>0.143868</td>\n",
       "      <td>...</td>\n",
       "      <td>369263</td>\n",
       "      <td>0.022799</td>\n",
       "      <td>2.197987</td>\n",
       "      <td>0.042352</td>\n",
       "      <td>668111</td>\n",
       "      <td>0.067013</td>\n",
       "      <td>2.197987</td>\n",
       "      <td>0.037324</td>\n",
       "      <td>23173</td>\n",
       "      <td>0.249262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72650</th>\n",
       "      <td>5915025.0</td>\n",
       "      <td>259715</td>\n",
       "      <td>259715</td>\n",
       "      <td>0.041700</td>\n",
       "      <td>65261</td>\n",
       "      <td>69153</td>\n",
       "      <td>0.161280</td>\n",
       "      <td>41</td>\n",
       "      <td>70224</td>\n",
       "      <td>0.148382</td>\n",
       "      <td>...</td>\n",
       "      <td>174255</td>\n",
       "      <td>0.027465</td>\n",
       "      <td>2.566490</td>\n",
       "      <td>0.028338</td>\n",
       "      <td>256726</td>\n",
       "      <td>0.069346</td>\n",
       "      <td>2.566490</td>\n",
       "      <td>0.057609</td>\n",
       "      <td>10830</td>\n",
       "      <td>0.259042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72680</th>\n",
       "      <td>5915029.0</td>\n",
       "      <td>81568</td>\n",
       "      <td>81568</td>\n",
       "      <td>0.039623</td>\n",
       "      <td>20019</td>\n",
       "      <td>20778</td>\n",
       "      <td>0.151651</td>\n",
       "      <td>30</td>\n",
       "      <td>17861</td>\n",
       "      <td>0.168244</td>\n",
       "      <td>...</td>\n",
       "      <td>35012</td>\n",
       "      <td>0.070547</td>\n",
       "      <td>2.246035</td>\n",
       "      <td>0.075488</td>\n",
       "      <td>80298</td>\n",
       "      <td>0.027535</td>\n",
       "      <td>2.246035</td>\n",
       "      <td>0.068863</td>\n",
       "      <td>3232</td>\n",
       "      <td>0.239294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>737 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            CODE  total_pop_1_SCALAR  total_pop_2_SCALAR  total_5_9  \\\n",
       "29477  5943816.0                 237                 237   0.071730   \n",
       "29537  5943817.0                   0                   0   0.000000   \n",
       "29597  5943835.0                  10                  10   0.200000   \n",
       "29657  5943836.0                  73                  73   0.068493   \n",
       "29717  5943837.0                 461                 461   0.047722   \n",
       "...          ...                 ...                 ...        ...   \n",
       "72557  5915015.0              216320              216320   0.041841   \n",
       "72588  5915020.0               19383               19383   0.045194   \n",
       "72619  5915022.0              682404              682404   0.033958   \n",
       "72650  5915025.0              259715              259715   0.041700   \n",
       "72680  5915029.0               81568               81568   0.039623   \n",
       "\n",
       "       total_fam_households_SCALAR  census_families_SCALAR  lone_parent  \\\n",
       "29477                           55                      59     0.152542   \n",
       "29537                            0                       0     0.000000   \n",
       "29597                            1                       2     0.500000   \n",
       "29657                            0                       0     0.000000   \n",
       "29717                          146                     146     0.328767   \n",
       "...                            ...                     ...          ...   \n",
       "72557                        57981                   62174     0.165873   \n",
       "72588                         4156                    4252     0.200611   \n",
       "72619                       162731                  171041     0.157477   \n",
       "72650                        65261                   69153     0.161280   \n",
       "72680                        20019                   20778     0.151651   \n",
       "\n",
       "       percent_children_home  total_kids_home_SCALAR  total_kids_home  ...  \\\n",
       "29477                     56                      80         0.212500  ...   \n",
       "29537                      0                       0         0.000000  ...   \n",
       "29597                    100                       3         0.000000  ...   \n",
       "29657                      0                       0         0.000000  ...   \n",
       "29717                     33                     162         0.135802  ...   \n",
       "...                      ...                     ...              ...  ...   \n",
       "72557                     48                   65889         0.131904  ...   \n",
       "72588                     42                    4677         0.177892  ...   \n",
       "72619                     29                  153585         0.143868  ...   \n",
       "72650                     41                   70224         0.148382  ...   \n",
       "72680                     30                   17861         0.168244  ...   \n",
       "\n",
       "       vis_minority_total_SCALAR  vis_minority_blk  house_pop_abrgnl  \\\n",
       "29477                          0          0.000000          3.246575   \n",
       "29537                          0          0.000000          0.000000   \n",
       "29597                          0          0.000000         10.000000   \n",
       "29657                          0          0.000000          4.000000   \n",
       "29717                          0          0.000000          1.822581   \n",
       "...                          ...               ...               ...   \n",
       "72557                     170221          0.009447          2.708127   \n",
       "72588                      12352          0.006477          2.526659   \n",
       "72619                     369263          0.022799          2.197987   \n",
       "72650                     174255          0.027465          2.566490   \n",
       "72680                      35012          0.070547          2.246035   \n",
       "\n",
       "       abrgnl_id  pop_knowledge_off_lang_SCALAR  no_off_lang  \\\n",
       "29477   0.000000                            237     0.000000   \n",
       "29537   0.000000                              0     0.000000   \n",
       "29597   0.000000                             10     0.000000   \n",
       "29657   0.000000                              4     0.000000   \n",
       "29717   0.000000                            452     0.000000   \n",
       "...          ...                            ...          ...   \n",
       "72557   0.011597                         214443     0.111176   \n",
       "72588   0.025502                          17439     0.063249   \n",
       "72619   0.042352                         668111     0.067013   \n",
       "72650   0.028338                         256726     0.069346   \n",
       "72680   0.075488                          80298     0.027535   \n",
       "\n",
       "       household_recent_immigrant  total_recent_immigrant  unscaled_5_9  \\\n",
       "29477                    3.246575                0.000000            17   \n",
       "29537                    0.000000                0.000000             0   \n",
       "29597                   10.000000                0.000000             2   \n",
       "29657                    4.000000                0.000000             5   \n",
       "29717                    1.822581                0.000000            22   \n",
       "...                           ...                     ...           ...   \n",
       "72557                    2.708127                0.061035          9051   \n",
       "72588                    2.526659                0.038745           876   \n",
       "72619                    2.197987                0.037324         23173   \n",
       "72650                    2.566490                0.057609         10830   \n",
       "72680                    2.246035                0.068863          3232   \n",
       "\n",
       "       low_income  \n",
       "29477    0.328767  \n",
       "29537    0.000000  \n",
       "29597    0.000000  \n",
       "29657    0.000000  \n",
       "29717    0.645161  \n",
       "...           ...  \n",
       "72557    0.257776  \n",
       "72588    0.393799  \n",
       "72619    0.249262  \n",
       "72650    0.259042  \n",
       "72680    0.239294  \n",
       "\n",
       "[737 rows x 28 columns]"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df_csd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "e86e81d9-4f50-4d12-ba82-bae4ae806777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display_cor_clusters(data_df_csd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "41c01b1c-393e-4ba9-83df-eda8bfbf6a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = [0.05, 0.05, 0.2, 0.1, 0.175, 0.1, 0.175, 0.15]\n",
    "forced_choices = ['household_recent_immigrant', 'vis_minority_blk', 'abrgnl_id', 'no_off_lang', 'low_income', 'median_income', 'lone_parent', 'total_kids_home']\n",
    "input_df = data_df_csd[['CODE'] + forced_choices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "a57b2229-c160-4448-b381-305f38d2f975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            CODE  household_recent_immigrant  vis_minority_blk  abrgnl_id  \\\n",
      "29477  5943816.0                    3.246575          0.000000   0.000000   \n",
      "29537  5943817.0                    0.000000          0.000000   0.000000   \n",
      "29597  5943835.0                   10.000000          0.000000   0.000000   \n",
      "29657  5943836.0                    4.000000          0.000000   0.000000   \n",
      "29717  5943837.0                    1.822581          0.000000   0.000000   \n",
      "...          ...                         ...               ...        ...   \n",
      "72557  5915015.0                    2.708127          0.009447   0.011597   \n",
      "72588  5915020.0                    2.526659          0.006477   0.025502   \n",
      "72619  5915022.0                    2.197987          0.022799   0.042352   \n",
      "72650  5915025.0                    2.566490          0.027465   0.028338   \n",
      "72680  5915029.0                    2.246035          0.070547   0.075488   \n",
      "\n",
      "       no_off_lang  low_income  median_income  lone_parent  total_kids_home  \n",
      "29477     0.000000    0.328767       56261.36     0.152542         0.212500  \n",
      "29537     0.000000    0.000000           0.00     0.000000         0.000000  \n",
      "29597     0.000000    0.000000       79381.78     0.500000         0.000000  \n",
      "29657     0.000000    0.000000      131401.23     0.000000         0.000000  \n",
      "29717     0.000000    0.645161       31636.67     0.328767         0.135802  \n",
      "...            ...         ...            ...          ...              ...  \n",
      "72557     0.111176    0.257776       77285.87     0.165873         0.131904  \n",
      "72588     0.063249    0.393799       57984.51     0.200611         0.177892  \n",
      "72619     0.067013    0.249262       80723.41     0.157477         0.143868  \n",
      "72650     0.069346    0.259042       76955.71     0.161280         0.148382  \n",
      "72680     0.027535    0.239294       76805.88     0.151651         0.168244  \n",
      "\n",
      "[737 rows x 9 columns]\n",
      "0 CODE\n",
      "1 household_recent_immigrant\n",
      "2 vis_minority_blk\n",
      "3 abrgnl_id\n",
      "4 no_off_lang\n",
      "5 low_income\n",
      "6 median_income\n",
      "7 lone_parent\n",
      "8 total_kids_home\n"
     ]
    }
   ],
   "source": [
    "table = create_score_table(input_df, 10, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "a2fc1eb8-4b35-4e7c-88d2-164914658caf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "656    0.000000\n",
       "725    0.000000\n",
       "553    0.000000\n",
       "653    0.000000\n",
       "136    0.000000\n",
       "         ...   \n",
       "288    0.000000\n",
       "423    0.004167\n",
       "3      0.000000\n",
       "611    0.018762\n",
       "608    0.013804\n",
       "Name: no_off_lang, Length: 737, dtype: float64"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table['no_off_lang']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de6f75c-42cf-4ba1-a44a-94ff23bc88e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "id": "d4bf77db-7d06-4729-ae52-40c8419c954f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: file path to the boundary shape file with CSD and Da\n",
    "# Ouput: A dataframe with two columns, one with CSDs and the other with the corresponding DA\n",
    "\n",
    "def get_csd_da_conversion(shape_path):\n",
    "    df_map= gpd.read_file('{}/lda_000a16a_e/lda_000a16a_e.shx'.format(shape_path))\n",
    "    df_map_bc = df_map[df_map['PRNAME'] =='British Columbia / Colombie-Britannique'].reset_index(drop=True)\n",
    "    return_df = df_map_bc[['DAUID', 'CSDUID', 'CSDNAME']]\n",
    "    return return_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "0966a73d-1a7d-4750-9cef-be0401b6cbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: file path to the postal code conversion file\n",
    "# Output: A dataframe with postal codes, dissemination areas, csds, and \n",
    "# information relating to the quality of the data\n",
    "\n",
    "\n",
    "def new_postal_da(pccf_path):\n",
    "    postal_codes = []\n",
    "    dissemination_areas = []\n",
    "    csds = []\n",
    "    quality = []\n",
    "    retired = []\n",
    "    sli = []\n",
    "    rpt = []\n",
    "    dmt = []\n",
    "    lat = []\n",
    "    lon = []\n",
    "    bd = []\n",
    "    source = []\n",
    "    # Open the file\n",
    "    with open(pccf_path, encoding = \"ISO-8859-1\") as file:\n",
    "        # Iterate through the file line by line\n",
    "        for line in file:\n",
    "            # If province is BC\n",
    "            if(line[9:11] == '59'):\n",
    "                \n",
    "                # Save the information of the line \n",
    "                postal_codes.append(line[0:6])\n",
    "                dissemination_areas.append(line[125:133])\n",
    "                csds.append(line[15:22])\n",
    "                quality.append(line[212:215])\n",
    "                retired.append(line[203:211])\n",
    "                sli.append(line[161:162])\n",
    "                rpt.append(line[136:137])\n",
    "                dmt.append(line[193:194])\n",
    "                lat.append(line[137: 148])\n",
    "                lon.append(line[148: 162])\n",
    "                bd.append(line[195:203])\n",
    "                source.append(line[215:216])\n",
    "                \n",
    "    # Create a dataframe from the saved information \n",
    "    d = {'postal' : postal_codes, 'da' : dissemination_areas, 'csd' : csds, 'quality' : quality, \n",
    "         'retired' : retired, 'rpt' : rpt, 'dmt' : dmt,'bd' : bd, 'source' : source}  \n",
    "    df1 = pd.DataFrame(data=d) \n",
    "    df2 = df1.drop_duplicates()\n",
    "    \n",
    "    # '19000001' refers to postal codes that are not expired\n",
    "    df3 = df2[df2.retired == '19000001']\n",
    "    \n",
    "    # Return all the postal codes that have a quality higher than \"No information\"\n",
    "    return df3[df3.quality != 'NNN']\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "id": "3b185c0b-f5ce-4ea3-b347-4adf8199adac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>postal</th>\n",
       "      <th>da</th>\n",
       "      <th>csd</th>\n",
       "      <th>quality</th>\n",
       "      <th>retired</th>\n",
       "      <th>rpt</th>\n",
       "      <th>dmt</th>\n",
       "      <th>bd</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>V0A0A0</td>\n",
       "      <td>59390219</td>\n",
       "      <td>5939007</td>\n",
       "      <td>BAA</td>\n",
       "      <td>19000001</td>\n",
       "      <td>1</td>\n",
       "      <td>W</td>\n",
       "      <td>20140601</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>V0A1H0</td>\n",
       "      <td>59390219</td>\n",
       "      <td>5939007</td>\n",
       "      <td>BAA</td>\n",
       "      <td>19000001</td>\n",
       "      <td>1</td>\n",
       "      <td>W</td>\n",
       "      <td>19830401</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>V0A1H3</td>\n",
       "      <td>59390218</td>\n",
       "      <td>5939007</td>\n",
       "      <td>BAA</td>\n",
       "      <td>19000001</td>\n",
       "      <td>1</td>\n",
       "      <td>W</td>\n",
       "      <td>20040701</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>V0A1H6</td>\n",
       "      <td>59390225</td>\n",
       "      <td>5939007</td>\n",
       "      <td>BAN</td>\n",
       "      <td>19000001</td>\n",
       "      <td>2</td>\n",
       "      <td>W</td>\n",
       "      <td>20040701</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>V0A1K4</td>\n",
       "      <td>59010132</td>\n",
       "      <td>5901039</td>\n",
       "      <td>BAA</td>\n",
       "      <td>19000001</td>\n",
       "      <td>1</td>\n",
       "      <td>W</td>\n",
       "      <td>19990701</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226166</th>\n",
       "      <td>V9Z1N9</td>\n",
       "      <td>59170657</td>\n",
       "      <td>5917052</td>\n",
       "      <td>BAN</td>\n",
       "      <td>19000001</td>\n",
       "      <td>2</td>\n",
       "      <td>A</td>\n",
       "      <td>20180501</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226168</th>\n",
       "      <td>V9Z1P1</td>\n",
       "      <td>59170668</td>\n",
       "      <td>5917052</td>\n",
       "      <td>BAA</td>\n",
       "      <td>19000001</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>20180501</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226170</th>\n",
       "      <td>V9Z1P2</td>\n",
       "      <td>59170668</td>\n",
       "      <td>5917052</td>\n",
       "      <td>BAN</td>\n",
       "      <td>19000001</td>\n",
       "      <td>2</td>\n",
       "      <td>A</td>\n",
       "      <td>20190801</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226172</th>\n",
       "      <td>V9Z1P5</td>\n",
       "      <td>59170664</td>\n",
       "      <td>5917052</td>\n",
       "      <td>BAB</td>\n",
       "      <td>19000001</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>20201101</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226175</th>\n",
       "      <td>V9Z2A1</td>\n",
       "      <td>59170652</td>\n",
       "      <td>5917052</td>\n",
       "      <td>BAA</td>\n",
       "      <td>19000001</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>20070901</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>89384 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        postal        da      csd quality   retired rpt dmt        bd source\n",
       "0       V0A0A0  59390219  5939007     BAA  19000001   1   W  20140601      1\n",
       "15      V0A1H0  59390219  5939007     BAA  19000001   1   W  19830401      1\n",
       "158     V0A1H3  59390218  5939007     BAA  19000001   1   W  20040701      1\n",
       "208     V0A1H6  59390225  5939007     BAN  19000001   2   W  20040701      1\n",
       "418     V0A1K4  59010132  5901039     BAA  19000001   1   W  19990701      1\n",
       "...        ...       ...      ...     ...       ...  ..  ..       ...    ...\n",
       "226166  V9Z1N9  59170657  5917052     BAN  19000001   2   A  20180501      1\n",
       "226168  V9Z1P1  59170668  5917052     BAA  19000001   1   A  20180501      1\n",
       "226170  V9Z1P2  59170668  5917052     BAN  19000001   2   A  20190801      1\n",
       "226172  V9Z1P5  59170664  5917052     BAB  19000001   1   A  20201101      1\n",
       "226175  V9Z2A1  59170652  5917052     BAA  19000001   1   A  20070901      1\n",
       "\n",
       "[89384 rows x 9 columns]"
      ]
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_postal_da(postal_da_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a298fd-8d0f-428b-b75b-eae076bb9bdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5341345-b439-43fc-8e1c-4ec3e4ec0a89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51397a34-5637-4307-9b82-accdf60953ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9192fc40-d7ad-49bb-bf51-048d9644edc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "id": "e1525aad-91bc-4654-853a-b61afb2be043",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_postal_da_conversion(pccf_path):\n",
    "    \n",
    "    postal_codes = []\n",
    "    dissemination_areas = []\n",
    "\n",
    "    with open(pccf_path, encoding = \"ISO-8859-1\") as file:\n",
    "        counter = 0\n",
    "        for line in file:\n",
    "            if line[9:11] == '59':\n",
    "                postal = line[0:6]\n",
    "                formatted = \" \".join(line.split())\n",
    "                found = False\n",
    "                start = 1\n",
    "                arr = formatted.split()\n",
    "                while not found and start < len(arr):\n",
    "                    splitted = arr[start]\n",
    "                    # print(splitted)\n",
    "                    if len(splitted) < 35:\n",
    "                        start += 1\n",
    "                    else:\n",
    "                        found = True\n",
    "\n",
    "\n",
    "                da = \"59\" + splitted[len(splitted) - 10:len(splitted)-4]\n",
    "                if counter < 10 and da == '59':\n",
    "                    print(formatted)\n",
    "                    counter += 1\n",
    "\n",
    "                if postal == 'V6A4K3':\n",
    "                    print(formatted)\n",
    "                    print(arr)\n",
    "                    print(splitted)\n",
    "                    print(found)\n",
    "\n",
    "                    # print(splitted[len(splitted)])\n",
    "                if found:\n",
    "                    postal_codes.append(postal)\n",
    "                    dissemination_areas.append(da)\n",
    "    d = {'postal' : postal_codes, 'da' : dissemination_areas}  \n",
    "    df = pd.DataFrame(data=d) \n",
    "    \n",
    "    removed_df = df[~df['postal'].duplicated(keep='first')]\n",
    "    \n",
    "    return removed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03efd9ca-b5f5-4e4c-814b-f7765abfac01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "e9be942d-154b-445c-909d-26bcafb5d450",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: Paths to the schools out location, and schools out data\n",
    "# Output: A dataframe with the list of locations split into separate rows and the data joined on\n",
    "\n",
    "def sa_locations(so_locations_path, so_data_path):\n",
    "    in_dir1 = so_locations_path\n",
    "    in_dir2 = so_data_path\n",
    "\n",
    "    locations = pd.read_csv(in_dir1)\n",
    "    locations=locations.dropna()\n",
    "    data = pd.read_csv(in_dir2)\n",
    "    \n",
    "    # Split the list of postal codes\n",
    "    locations[\"Postal Codes\"] = locations[\"Postal Codes\"].apply(split_fn)\n",
    "    \n",
    "    # Create a row for each postal code\n",
    "    locations = locations.explode(\"Postal Codes\")\n",
    "    \n",
    "    # Drop rows which have no postal codes\n",
    "    locations = locations[locations[\"Postal Codes\"] != \"on Microsoft Teams and Zoom\"]\n",
    "    \n",
    "    # Join the two tables based on the name of the program\n",
    "    result = pd.merge(locations, data, how=\"left\", on=[\"Unnamed: 0\"])\n",
    "    result = result.rename(columns={\"Unnamed: 0\": \"Name\"})\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9918ed8b-d62b-45ce-85bc-f8780a13b785",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "id": "33aa2f7f-6818-45d2-9f40-e32bcafdd643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: file paths to bc authorized childcare programs, schools out locations, \n",
    "# schools out data, postal code conversion, and boundary shape files\n",
    "# Output: A dataframe with the DA, CSD, location name, and number of services for each area \n",
    "# Also prints the percentage of located services\n",
    "\n",
    "def agency_table(bc_ccare_path, so_locations_path, so_data_path, pccf_path, shape_path):\n",
    "    locations = pd.read_csv(bc_ccare_path)\n",
    "    SO_locations = sa_locations(so_locations_path, so_data_path)\n",
    "    \n",
    "    # Get the postal DA conversion\n",
    "    postal = new_postal_da(pccf_path)\n",
    "    postal['postal'] = postal['postal'].apply(add_space)\n",
    "    \n",
    "    # Format the schools out location postal codes\n",
    "    SO_locations['Postal Codes']= SO_locations['Postal Codes'].str.replace('!','1',regex=True)\n",
    "    SO_locations['Postal Codes'] = SO_locations['Postal Codes'].apply(add_space)\n",
    "    SO_locations['Postal Codes'] = SO_locations['Postal Codes'].apply(to_upper)\n",
    "    \n",
    "    # Join the schools out table and postal code table on postal code\n",
    "    new_df = SO_locations.merge(postal, left_on='Postal Codes', right_on='postal')\n",
    "    \n",
    "    # prints the percentage of located services\n",
    "    print(\"Found: {}% of the Schools out locations\".format(len(new_df) / len(SA_locations)))\n",
    "    \n",
    "    \n",
    "    SO_postal_da = new_df[['postal', 'da', 'Agency Name']]\n",
    "    SO_postal_da = SO_postal_da.rename(columns={'Agency Name' : 'NAME'})\n",
    "    \n",
    "    # Join the bc authorized locations with the postal DA conversion\n",
    "    locations_postal_da = locations.merge(postal, left_on='POSTAL_CODE', right_on='postal')[['postal', 'da', 'NAME']]\n",
    "    \n",
    "    # prints the percentage of located services\n",
    "    print(\"Found: {}% of the BC programs\".format(len(locations_postal_da) / len(locations)))\n",
    "    \n",
    "    # Combine both tables together and drop duplicates\n",
    "    combined_postal_da = pd.concat([SO_postal_da, locations_postal_da])\n",
    "    combined_postal_da = combined_postal_da.drop_duplicates()\n",
    "    \n",
    "    # Get the CSD/DA conversion from the boundary shape file\n",
    "    csd_da_con = get_csd_da_conversion(shape_path)\n",
    "    csd_da_con['DAUID'] = csd_da_con['DAUID'].astype(str)\n",
    "    \n",
    "    # Join the CSD info on the combine table\n",
    "    csd_info = combined_postal_da.merge(csd_da_con, left_on='da', right_on='DAUID')\n",
    "    \n",
    "    # Count the number of services in each CSD\n",
    "    count_csd = csd_info.groupby('CSDUID').count()\n",
    "    counted = csd_info.merge(count_csd['postal'], left_on='CSDUID', right_index = True).rename(columns={'postal_y': \"num_childcare_services\"})\n",
    "    counted = counted[['DAUID', 'CSDUID', 'num_childcare_services', 'CSDNAME']]\n",
    "    \n",
    "    dropped = counted.drop_duplicates()\n",
    "    \n",
    "    return dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "a61bda4a-d54b-4be8-ac2b-d8cb6cd26913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found: 0.7075471698113207% of the Schools out locations\n",
      "Found: 0.6297658215598994% of the BC programs\n",
      "     postal_x        da                                          NAME  \\\n",
      "0     V7P 2B9  59150115           Capilano Community Services Society   \n",
      "1     V7P 2C9  59150115                        Kiddies Palace Daycare   \n",
      "2     V7P 2B9  59150115                           Capilano Kids' Club   \n",
      "3     V7P 1L9  59150071           Capilano Community Services Society   \n",
      "4     V7P 1L9  59150071                Red Fox Healthy Living Society   \n",
      "...       ...       ...                                           ...   \n",
      "2898  V0A 1K5  59010125             Rural Roots Early Learning Centre   \n",
      "2913  V4V 1S7  59350270  Okanagan Boys And Girls Clubs - Lake Country   \n",
      "2922  V9A 7K7  59170332                  K'wenskwen Child Care Center   \n",
      "3035  V0R 1X3  59210470                               The Hope Centre   \n",
      "3097  V0C 2W0  59550233               Tumbler Ridge Children's Center   \n",
      "\n",
      "         DAUID   CSDUID          CSDNAME  num_childcare_services  \n",
      "0     59150115  5915046  North Vancouver                      95  \n",
      "1     59150115  5915046  North Vancouver                      95  \n",
      "2     59150115  5915046  North Vancouver                      95  \n",
      "3     59150071  5915046  North Vancouver                      95  \n",
      "4     59150071  5915046  North Vancouver                      95  \n",
      "...        ...      ...              ...                     ...  \n",
      "2898  59010125  5901048  East Kootenay G                       1  \n",
      "2913  59350270  5935801      Duck Lake 7                       1  \n",
      "2922  59170332  5917811        Esquimalt                       1  \n",
      "3035  59210470  5921014        Nanaimo B                       1  \n",
      "3097  59550233  5955003    Tumbler Ridge                       1  \n",
      "\n",
      "[3190 rows x 7 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DAUID</th>\n",
       "      <th>CSDUID</th>\n",
       "      <th>num_childcare_services</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59150115</td>\n",
       "      <td>5915046</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59150071</td>\n",
       "      <td>5915046</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>59150136</td>\n",
       "      <td>5915046</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>59153573</td>\n",
       "      <td>5915046</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>59150252</td>\n",
       "      <td>5915046</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2898</th>\n",
       "      <td>59010125</td>\n",
       "      <td>5901048</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2913</th>\n",
       "      <td>59350270</td>\n",
       "      <td>5935801</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2922</th>\n",
       "      <td>59170332</td>\n",
       "      <td>5917811</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3035</th>\n",
       "      <td>59210470</td>\n",
       "      <td>5921014</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3097</th>\n",
       "      <td>59550233</td>\n",
       "      <td>5955003</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         DAUID   CSDUID  num_childcare_services\n",
       "0     59150115  5915046                      95\n",
       "3     59150071  5915046                      95\n",
       "259   59150136  5915046                      95\n",
       "275   59153573  5915046                      95\n",
       "336   59150252  5915046                      95\n",
       "...        ...      ...                     ...\n",
       "2898  59010125  5901048                       1\n",
       "2913  59350270  5935801                       1\n",
       "2922  59170332  5917811                       1\n",
       "3035  59210470  5921014                       1\n",
       "3097  59550233  5955003                       1\n",
       "\n",
       "[2000 rows x 3 columns]"
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agency_table(bc_ccare_path, so_locations_path, \n",
    "             so_data_path, postal_da_path, shape_path)[['DAUID', 'CSDUID', 'num_childcare_services']]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "21ae8e02-7460-4c8e-9765-26867768dd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_csd_da_conversion(shape_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fa2dd5-f70f-49d1-8bfa-55bfb8fe5495",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "id": "9c73f03f-94b8-49ce-9d91-97d096a99bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input \n",
    "\n",
    "def score_supply(agent_table, con_table, agg_type):\n",
    "    scored = agent_table.merge(con_table, how='right', right_on=agg_type, left_on=agg_type)\n",
    "    \n",
    "    print(agent_table, con_table)\n",
    "    scored.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    scored = scored.fillna(0)\n",
    "    scored = scored.rename(columns={'CSDNAME_y' : 'CSDNAME'})\n",
    "    # Should we include this part?\n",
    "    if agg_type == 'CSDUID':\n",
    "        scored = scored[['num_childcare_services', 'CSDUID', 'CSDNAME']]\n",
    "        scored = scored.drop_duplicates()\n",
    "    else:\n",
    "        scored=scored.drop('CSDUID_x', axis=1)\n",
    "        scored = scored.rename(columns={'CSDUID_y' : 'CSDUID'})\n",
    "        \n",
    "    print(scored)\n",
    "    return scored\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "id": "3f46f9cc-80fc-4f46-8ffe-7a4e3e0a10c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTES: This is information that needs to be saved in the mega-csv (or a separate csv file)\n",
    "# Input: the table of scores for each area, the geography to consider, number of intervals, and path to the \n",
    "# Environics data\n",
    "# Output: A table with the supply scores for each area\n",
    "\n",
    "def scale_score_supply(score_table, agg_type, intervals, environics_path):\n",
    "    in_dir1 = environics_path\n",
    "    data = pd.read_csv(in_dir1)\n",
    "    \n",
    "    if agg_type == 'DAUID':\n",
    "        data = data[data.GEO == 'PRCDDA']\n",
    "    else:\n",
    "        data = data[data.GEO == 'PRCDCSD']\n",
    "    \n",
    "    data['CODE']=data['CODE'].astype(int)\n",
    "    score_table[agg_type]=score_table[agg_type].astype(int)\n",
    "    score_table = score_table[[agg_type, 'num_childcare_services', 'CSDNAME']]\n",
    "        \n",
    "    data = data.merge(score_table, left_on='CODE', right_on=agg_type)\n",
    "    data['scaled_num_services'] = data['num_childcare_services'] / (data['ECYPTA_5_9'] + data['ECYPTA1014'])\n",
    "    data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    data = data.fillna(0)\n",
    "    \n",
    "    \n",
    "    data = data[[agg_type, 'num_childcare_services', 'scaled_num_services', 'CSDNAME']]\n",
    "    \n",
    "    n = intervals\n",
    "    meta_data = {}\n",
    "    meta_data['scaled_num_services'] = (data['scaled_num_services'].max() - data['scaled_num_services'].min()) / n\n",
    "    data['supply_score'] = 0\n",
    "    for i in range(n):\n",
    "        data['supply_score'][data['scaled_num_services'].between(meta_data.get('scaled_num_services') * i, meta_data.get('scaled_num_services') * (i + 1))] = (i+1)\n",
    "    \n",
    "    data['supply_score'] /= 10\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "id": "e794c175-4f57-465b-9a9a-8d2d872ad28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTES: This is information that needs to be saved in the mega-csv (or a separate csv file)\n",
    "# Input: Dataframes of supply scores, demand scores, agg_type = (DA, CSD), and boolean with_supply to compute\n",
    "# need scores with or without considering supply\n",
    "# Output: A Dataframe with the need scores for each area\n",
    "\n",
    "def total_scores(supply, demand, agg_type, with_supply):\n",
    "    supply[agg_type] = supply[agg_type].astype(int)\n",
    "    demand['CODE'] = demand['CODE'].astype(int)\n",
    "    full_data = demand.merge(supply, left_on='CODE', right_on=agg_type)\n",
    "    if with_supply:\n",
    "        full_data['diff'] = full_data['supply_score'] - full_data['percent_total']\n",
    "    else:\n",
    "        full_data['diff'] = 1 - full_data['percent_total']\n",
    "    \n",
    "    return full_data[['CODE', 'diff']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "id": "330cc104-7703-4bce-af6a-4fe67a07be6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_map(total_scores, agg_type, shape_path, col_name):\n",
    "    if agg_type == 'CSDUID':\n",
    "        mp = gpd.read_file('{}/lcsd000a16a_e/lcsd000a16a_e.shx'.format(shape_path))\n",
    "    else:\n",
    "        mp = gpd.read_file('{}/lda_000a16a_e/lda_000a16a_e.shx'.format(shape_path))\n",
    "    mp = mp[mp['PRNAME'] =='British Columbia / Colombie-Britannique'].reset_index(drop=True)\n",
    "    \n",
    "    # mp = mp[mp['CDUID'] == '5909']\n",
    "    \n",
    "    # mp = mp.merge(total_scores, left_on='CSDUID', right_index = True)\n",
    "    scores = total_scores[[col_name]]\n",
    "    mp['scores'] = scores\n",
    "    print(mp)\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(20,20))\n",
    "    mp.plot(column='scores', ax=ax, legend=True, cmap='OrRd')\n",
    "    # plt.savefig('bc.png')\n",
    "    # df_map5.show()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "id": "deb91ed0-0b49-4d30-b5c7-4ee985b09350",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "id": "bb2318ef-4603-4cd1-a43c-eded71550c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(args):\n",
    "    \n",
    "    # Here is where we can change the variables and the weights\n",
    "    \n",
    "    if args == 'DA':\n",
    "    \n",
    "        weights = [0.2, 0.2, 0.2, 0.16, 0.12, 0.12]\n",
    "        # weights = [1, 1, 1, 1, 1, 1]\n",
    "        forced_choices = ['vis_minority_blk', 'house_pop_abrgnl', 'total_recent_immigrant', 'median_income', 'lone_parent', 'total_kids']\n",
    "    else:\n",
    "        \n",
    "        # 0.13 * household_recent_immigrant, 0.13 * vis_minority_blk, 0.13 * abrgnl_id, \n",
    "        # 0.125 * no_off_lang, 0.125 * low_income, 0.125 * median_income, 0.1175 * lone_parent, \n",
    "        # 0.1175 * kids_home_5_9 \n",
    "        # weights = [1, 1, 1, 1, 1, 1, 1, 1]\n",
    "        \n",
    "        # Paper submission version\n",
    "        # weights = [0.13, 0.13, 0.13, 0.125, 0.125, 0.125, 0.1175, 0.1175]\n",
    "        # forced_choices = ['household_recent_immigrant', 'vis_minority_blk', 'abrgnl_id', 'no_off_lang', 'low_income', 'median_income', 'lone_parent', 'total_kids_home']\n",
    "        # Pronounced Weights Indigenous communities:\n",
    "        weights = [0.05, 0.05, 0.2, 0.1, 0.175, 0.1, 0.175, 0.15]\n",
    "        forced_choices = ['household_recent_immigrant', 'vis_minority_blk', 'abrgnl_id', 'no_off_lang', 'low_income', 'median_income', 'lone_parent', 'total_kids_home']\n",
    "        \n",
    "\n",
    "        # Without kids 10-14\n",
    "        # forced_choices = ['household_recent_immigrant', 'vis_minority_blk', 'abrgnl_id', 'no_off_lang', \n",
    "        # 'low_income', 'median_income', 'lone_parent', 'kids_home_5_9'] \n",
    "        \n",
    "        # Without poverty statistics\n",
    "        # weights = [0.2, 0.2, 0.2, 0.16, 0.12, 0.12]\n",
    "        # forced_choices = ['household_recent_immigrant', 'vis_minority_blk', 'abrgnl_id', 'no_off_lang', 'lone_parent', 'total_kids_home']\n",
    "\n",
    "        # Without aboriginal community \n",
    "        # weights = [0.195, 0.195, 0.125, 0.125, 0.125, 0.1175, 0.1175]\n",
    "        # forced_choices = ['household_recent_immigrant', 'vis_minority_blk', 'no_off_lang', 'low_income', 'median_income', 'lone_parent', 'total_kids_home']\n",
    "        \n",
    "        # With kids 10-14\n",
    "        # forced_choices = ['household_recent_immigrant', 'abrgnl_id', 'vis_minority_blk', 'no_off_lang', 'median_income', 'low_income', 'lone_parent', 'total_kids_home']\n",
    "\n",
    "        \n",
    "    \n",
    "    bc_ccare_path = '402DATA/childcare_locations.csv'\n",
    "    environics_path = \"402DATA/SFU_CommunityImpactSO/EnvironicsData/DemoStats_2020_SelectVarsData.csv\"\n",
    "    so_locations_path = \"402DATA/SFU_CommunityImpactSO/SchoolsOutData/SO_map.csv\"\n",
    "    so_data_path = \"402DATA/SFU_CommunityImpactSO/SchoolsOutData/SO_DirectMetrics.csv\"\n",
    "    pccf_path = '402DATA/dataverse_files/Data/pccfNat_fccpNat_082021.txt'\n",
    "    shape_path = '402DATA/SFU_CommunityImpactSO/GeoData/BoundaryShapeFiles'\n",
    "    \n",
    "    interval_num = 10\n",
    "    num_vars = len(weights)\n",
    "    \n",
    "    if args == 'DA':\n",
    "        pr_code = 'PRCDDA'\n",
    "        agg_type = 'DAUID'\n",
    "    elif args == 'CSD':\n",
    "        pr_code = 'PRCDCSD'\n",
    "        agg_type = 'CSDUID'\n",
    "        \n",
    "    df1 = pd.read_csv(environics_path)\n",
    "\n",
    "    \n",
    "    drop_list = [total_area, total_land_area, total_60_64, total_65_69, total_70_74, total_75_79, \n",
    "                 total_80_84, total_85_plus, total_65_alone, house_pop_5_year_mobility,  movers, \n",
    "                 household_tenure, rented, band_housing, total_condo_status, in_condo, rented_in_condo, \n",
    "                 income_40_59, income_60_79, income_80_100, fifteen_older_income, without_income, \n",
    "                 kids_home_10_14, total_10_14, lp_one_child, lp_two_child, lp_three_more_child]\n",
    "    \n",
    "    df = rename(scale_and_drop(get_rows(df1, pr_code), drop_list))\n",
    "    df_choice = df[['CODE'] + forced_choices]\n",
    "    \n",
    "    demand = create_score_table(df_choice, num_vars, interval_num, weights)\n",
    "    \n",
    "    print(demand.sort_values(by='total').head(20))\n",
    "    print()\n",
    "    \n",
    "    counted = agency_table(bc_ccare_path, so_locations_path, so_data_path, pccf_path, shape_path)\n",
    "    csd_da = get_csd_da_conversion(shape_path)\n",
    "    score_table = score_supply(counted, csd_da, agg_type)\n",
    "    supply = scale_score_supply(score_table, agg_type, interval_num, environics_path)\n",
    "    \n",
    "    with_supply = True\n",
    "    totals = total_scores(supply, demand, agg_type, with_supply)\n",
    "    \n",
    "    minimum = totals['diff'].min()\n",
    "    maximum = totals['diff'].max()\n",
    "    totals['diff'] = totals['diff'].apply(normalize, args=(maximum, minimum,))\n",
    "    \n",
    "    \n",
    "    # totals['total'][totals['total_kids_home'] == 0] = 0\n",
    "    \n",
    "#     totals['CODE'] = totals['CODE'].astype(int)\n",
    "#     csd_da['DAUID'] = csd_da['DAUID'].astype(int)\n",
    "    \n",
    "#     totals['diff'][totals['diff'] >= 0.90] = 1\n",
    "\n",
    "    \n",
    "#     totals = totals.merge(csd_da, left_on='CODE', right_on='DAUID')\n",
    "#     totals = totals[['diff', 'CSDUID', 'total_kids']]\n",
    "#     totals = totals.groupby('CSDUID').median()\n",
    "    \n",
    "    totals['diff'][totals['total_kids_home'] == 0] = 0\n",
    "    print(totals)\n",
    "    display_map(totals, 'CSDUID', shape_path, 'diff')\n",
    "\n",
    "    \n",
    "    print(\"printing diff\")\n",
    "\n",
    "    sorted_totals = totals.sort_values(by='diff', ascending=False)\n",
    "    print(sorted_totals[['diff', 'CSDUID']].head(20))\n",
    "    # print(sorted_totals[sorted_totals['diff'] == 1])\n",
    "    \n",
    "    # print(\"printing totals\")\n",
    "    # sorted_totals = totals.sort_values(by='total', ascending=False)\n",
    "    # print(sorted_totals.head(20))\n",
    "    \n",
    "    return sorted_totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "id": "aed58681-2aca-4fde-8c26-f2f3c0b4c513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# totals = main('CSD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "id": "a1f78796-3d88-4a18-9d5c-45c5706ac32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from bs4 import BeautifulSoup\n",
    "# from requests_html import HTMLSession\n",
    "# from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "id": "de114721-d94b-42b4-af21-8926331046e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # initialize an HTTP session\n",
    "# session = HTMLSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "id": "7463d05a-0b3b-4cda-bb7d-391ff4297e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_all_forms(url):\n",
    "#     \"\"\"Returns all form tags found on a web page's `url` \"\"\"\n",
    "#     # GET request\n",
    "#     res = session.get(url)\n",
    "#     # for javascript driven website\n",
    "#     res.html.render()\n",
    "#     soup = BeautifulSoup(res.html.html, \"html.parser\")\n",
    "#     return soup.find_all(\"div\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "id": "ed6309db-a101-46f0-80e7-bbd9af6ed1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_all_forms('https://www12.statcan.gc.ca/census-recensement/2016/geo/geosearch-georecherche/index-eng.cfm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "id": "80459e72-4d8b-4bbe-a21b-dbbd047acb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "\n",
    "# url = 'https://www12.statcan.gc.ca/census-recensement/2016/geo/geosearch-georecherche/index-eng.cfm'\n",
    "# myobj = {'dijitReset dijitInputInner': 'V0N2H1'}\n",
    "\n",
    "# x = requests.post(url, json = myobj)\n",
    "\n",
    "# print(x.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "id": "18e0c28e-332a-41c6-aa69-3ae1193cf5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "bc_ccare_path = \"~/Desktop/code/Math402W/402DATA/childcare_locations.csv\"\n",
    "environics_path = \"~/Desktop/code/Math402W/402DATA/SFU_CommunityImpactSO/EnvironicsData/DemoStats_2020_SelectVarsData.csv\"\n",
    "so_locations_path = \"~/Desktop/code/Math402W/402DATA/SFU_CommunityImpactSO/SchoolsOutData/SO_map.csv\"\n",
    "so_data_path = \"~/Desktop/code/Math402W/402DATA/SFU_CommunityImpactSO/SchoolsOutData/SO_DirectMetrics.csv\"\n",
    "shape_path = \"~/Desktop/code/Math402W/402DATA/SFU_CommunityImpactSO/GeoData/BoundaryShapeFiles\"\n",
    "postal_da_path = r\"/Users/evanvulliamy/Desktop/code/Math402W/402DATA/dataverse_files/Data/pccfNat_fccpNat_082021.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "id": "f5dc051a-dfd7-4dac-bcf3-dc2889f23d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_main(bc_ccare_path, environics_path, so_locations_path, so_data_path, shape_path, postal_da_path):\n",
    "    \n",
    "    # Change args to be input into new_main\n",
    "    args = 'CSD'\n",
    "    interval_num = 10\n",
    "\n",
    "    if args == 'DA':\n",
    "        pr_code = 'PRCDDA'\n",
    "        agg_type = 'DAUID'\n",
    "    elif args == 'CSD':\n",
    "        pr_code = 'PRCDCSD'\n",
    "        agg_type = 'CSDUID'\n",
    "    \n",
    "    # Create the dataframes based on the paths\n",
    "\n",
    "    bc_ccare_df = pd.read_csv(bc_ccare_path)\n",
    "    environics_df = pd.read_csv(environics_path)\n",
    "    so_locations_df = pd.read_csv(so_locations_path)\n",
    "    so_data_df = pd.read_csv(so_data_path)\n",
    "    \n",
    "    # Get correct rows (province and geographic region)\n",
    "    \n",
    "    CSD = get_rows(environics_df, \"PRCDCSD\") # PRCDDA for dissemination areas    \n",
    "    \n",
    "    # List of variables that can be dropped \n",
    "    drop_list = [total_area, total_land_area, total_60_64, total_65_69, total_70_74, total_75_79, \n",
    "     total_80_84, total_85_plus, total_65_alone, house_pop_5_year_mobility,  movers, \n",
    "     household_tenure, rented, band_housing, total_condo_status, in_condo, rented_in_condo, \n",
    "     income_40_59, income_60_79, income_80_100, fifteen_older_income, without_income, \n",
    "     kids_home_10_14, total_10_14, lp_one_child, lp_two_child, lp_three_more_child, cf_with_children]\n",
    "    \n",
    "    # Scale the variables and drop variables in drop_list\n",
    "    data_df_csd = scale_and_drop(CSD, drop_list)\n",
    "    \n",
    "    # ADD CODE TO SAVE CLUSTERS AS CSV\n",
    "    # Should variable selection and scoring be two separate branches?\n",
    "    \n",
    "    # display_cor_clusters(data_df_csd)\n",
    "    \n",
    "    \n",
    "    # Chose weights and variables based on corelation clusters\n",
    "    weights = [0.05, 0.05, 0.2, 0.1, 0.175, 0.1, 0.175, 0.15]\n",
    "    choices = ['household_recent_immigrant', 'vis_minority_blk', 'abrgnl_id', 'no_off_lang', 'low_income', 'median_income', 'lone_parent', 'total_kids_home']\n",
    "    input_df = data_df_csd[['CODE'] + choices]\n",
    "    \n",
    "    # Create demand scores\n",
    "    table = create_score_table(input_df, 10, weights)\n",
    "    merged_table = table.merge(data_df_csd, on='CODE')\n",
    "    \n",
    "    # Create table for different childcare locations\n",
    "    counted = agency_table(bc_ccare_path, so_locations_path, so_data_path, postal_da_path, shape_path)\n",
    "    # Create table to link csd to da\n",
    "    csd_da = get_csd_da_conversion(shape_path)\n",
    "    \n",
    "    # Create supply scores\n",
    "    score_table = score_supply(counted, csd_da, agg_type)\n",
    "    supply = scale_score_supply(score_table, agg_type, interval_num, environics_path)\n",
    "    merged_table = supply.merge(merged_table, left_on='CSDUID', right_on = 'CODE')\n",
    "    \n",
    "    # Create total scores\n",
    "    with_supply = True\n",
    "    totals = total_scores(supply, table, agg_type, with_supply)\n",
    "    merged_table = totals.merge(merged_table, on = 'CODE')\n",
    "    \n",
    "    # Apply Normalization\n",
    "    minimum = totals['diff'].min()\n",
    "    maximum = totals['diff'].max()\n",
    "    merged_table['normalized'] = merged_table['diff'].apply(normalize, args=(maximum, minimum,))\n",
    "    \n",
    "    \n",
    "    merged_table = merged_table.drop('CSDUID', axis = 1)\n",
    "    \n",
    "    merged_table['is_num'] = merged_table['CSDNAME'].apply(get_last_word)\n",
    "    \n",
    "    \n",
    "    # Order the columns\n",
    "    \n",
    "    code = ['CODE', 'CSDNAME', 'is_num']\n",
    "    scalars = []\n",
    "    unused_vars = []\n",
    "    unscaled_scores = []\n",
    "    weighted_scores = []\n",
    "    total_need = ['total', 'percent_total']\n",
    "    supply = ['num_childcare_services', 'scaled_num_services', 'supply_score']\n",
    "    results = ['diff', 'normalized']\n",
    "    \n",
    "    for col in merged_table.columns:\n",
    "        if 'SCALAR' in col:\n",
    "            scalars.append(col)\n",
    "        \n",
    "        if 'unscaled' in col and col != 'unscaled_5_9':\n",
    "            unscaled_scores.append(col)\n",
    "            \n",
    "        if 'weighted' in col:\n",
    "            weighted_scores.append(col)\n",
    "                \n",
    "    for col in data_df_csd.columns:\n",
    "        if col not in scalars and col not in choices and col != 'CODE':\n",
    "            unused_vars.append(col)\n",
    "            \n",
    "    merged_table[code + scalars + unused_vars + choices + unscaled_scores \n",
    "                       + weighted_scores + total_need + supply + results][merged_table.is_num == True].to_csv('test.csv', index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "id": "a4b8dc45-81d8-4a9d-b268-233827e3c3fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found: 0.7075471698113207% of the Schools out locations\n",
      "Found: 0.6297658215598994% of the BC programs\n",
      "     postal_x        da                                          NAME  \\\n",
      "0     V7P 2B9  59150115           Capilano Community Services Society   \n",
      "1     V7P 2C9  59150115                        Kiddies Palace Daycare   \n",
      "2     V7P 2B9  59150115                           Capilano Kids' Club   \n",
      "3     V7P 1L9  59150071           Capilano Community Services Society   \n",
      "4     V7P 1L9  59150071                Red Fox Healthy Living Society   \n",
      "...       ...       ...                                           ...   \n",
      "2898  V0A 1K5  59010125             Rural Roots Early Learning Centre   \n",
      "2913  V4V 1S7  59350270  Okanagan Boys And Girls Clubs - Lake Country   \n",
      "2922  V9A 7K7  59170332                  K'wenskwen Child Care Center   \n",
      "3035  V0R 1X3  59210470                               The Hope Centre   \n",
      "3097  V0C 2W0  59550233               Tumbler Ridge Children's Center   \n",
      "\n",
      "         DAUID   CSDUID          CSDNAME  num_childcare_services  \n",
      "0     59150115  5915046  North Vancouver                      95  \n",
      "1     59150115  5915046  North Vancouver                      95  \n",
      "2     59150115  5915046  North Vancouver                      95  \n",
      "3     59150071  5915046  North Vancouver                      95  \n",
      "4     59150071  5915046  North Vancouver                      95  \n",
      "...        ...      ...              ...                     ...  \n",
      "2898  59010125  5901048  East Kootenay G                       1  \n",
      "2913  59350270  5935801      Duck Lake 7                       1  \n",
      "2922  59170332  5917811        Esquimalt                       1  \n",
      "3035  59210470  5921014        Nanaimo B                       1  \n",
      "3097  59550233  5955003    Tumbler Ridge                       1  \n",
      "\n",
      "[3190 rows x 7 columns]\n",
      "         DAUID   CSDUID  num_childcare_services          CSDNAME\n",
      "0     59150115  5915046                      95  North Vancouver\n",
      "3     59150071  5915046                      95  North Vancouver\n",
      "259   59150136  5915046                      95  North Vancouver\n",
      "275   59153573  5915046                      95  North Vancouver\n",
      "336   59150252  5915046                      95  North Vancouver\n",
      "...        ...      ...                     ...              ...\n",
      "2898  59010125  5901048                       1  East Kootenay G\n",
      "2913  59350270  5935801                       1      Duck Lake 7\n",
      "2922  59170332  5917811                       1        Esquimalt\n",
      "3035  59210470  5921014                       1        Nanaimo B\n",
      "3097  59550233  5955003                       1    Tumbler Ridge\n",
      "\n",
      "[2000 rows x 4 columns]          DAUID   CSDUID              CSDNAME\n",
      "0     59050100  5905014                Trail\n",
      "1     59050101  5905026  Kootenay Boundary A\n",
      "2     59050102  5905009             Montrose\n",
      "3     59050103  5905009             Montrose\n",
      "4     59050105  5905014                Trail\n",
      "...        ...      ...                  ...\n",
      "7612  59550156  5955014         Dawson Creek\n",
      "7613  59550157  5955014         Dawson Creek\n",
      "7614  59550158  5955014         Dawson Creek\n",
      "7615  59550159  5955014         Dawson Creek\n",
      "7616  59550160  5955014         Dawson Creek\n",
      "\n",
      "[7617 rows x 3 columns]\n",
      "        num_childcare_services   CSDUID              CSDNAME\n",
      "0                          5.0  5905014                Trail\n",
      "4                          0.0  5905026  Kootenay Boundary A\n",
      "5                          0.0  5905009             Montrose\n",
      "11                        19.0  5907041            Penticton\n",
      "25                         1.0  5907005              Osoyoos\n",
      "...                        ...      ...                  ...\n",
      "574982                    11.0  5955014         Dawson Creek\n",
      "574999                     0.0  5959810      Prophet River 4\n",
      "575000                     0.0  5959805             Fontas 1\n",
      "575001                     0.0  5959809            Kahntah 3\n",
      "575002                     0.0  5959806        Fort Nelson 2\n",
      "\n",
      "[737 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "new_main(bc_ccare_path, environics_path, so_locations_path, so_data_path, shape_path, postal_da_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522e05ec-0ad6-4f1e-a284-6bab6143988f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f6944e-aa77-4ad1-be63-2840a7f07b5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
